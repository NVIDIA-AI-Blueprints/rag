{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video/Document Continuous Ingestion from Object Storage\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook demonstrates an **automated document and video ingestion pipeline** that:\n",
    "\n",
    "1. Monitors emulated object storage for new uploads via Kafka events\n",
    "2. Routes files to appropriate AI services based on file type, currently supports document and video ingestion\n",
    "5. Enables RAG Agent for semantic search and contextual Q&A over all ingested content\n",
    "\n",
    "## What Gets Deployed\n",
    "\n",
    "1. **NVIDIA RAG** - Document indexing, vector search, and AI-powered Q&A (NIMs, Milvus, Ingestor)\n",
    "2. **NVIDIA VSS** - Video understanding and summarization (VLM, LLM NIMs, VSS Engine)\n",
    "3. **Continuous Ingestion** - Event-driven ingestion pipeline (Kafka, MinIO, Consumer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### Hardware\n",
    "- **GPU**: 8x RTX PRO 6000 Blackwell\n",
    "\n",
    "### Software (pre-installed required)\n",
    "- Ubuntu 22.04 or later\n",
    "- Docker 24.0+ with Docker Compose v2\n",
    "- NVIDIA Driver 570+\n",
    "- NVIDIA Container Toolkit\n",
    "\n",
    "### API Keys\n",
    "\n",
    "<table style=\"margin-left: 0;\">\n",
    "<tr><th>Key</th><th>Purpose</th><th>How to Get</th></tr>\n",
    "<tr><td><code>NGC_API_KEY</code></td><td>Docker login, NIM deployments</td><td><a href=\"https://org.ngc.nvidia.com/setup/api-keys\">NGC Portal</a> â†’ Generate API Key</td></tr>\n",
    "<tr><td><code>HF_TOKEN</code></td><td>Download VSS models</td><td><a href=\"https://huggingface.co/settings/tokens\">HuggingFace Tokens</a> â†’ Create token with Read access</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<table style=\"margin-left: 0;\">\n",
    "<tr><th>Section</th><th>Description</th></tr>\n",
    "<tr><td><b>Setup</b></td><td>Clone repo, install deps, set API keys, load helpers</td></tr>\n",
    "<tr><td><b>Deploy RAG</b></td><td>NIMs, Vector DB, Ingestor, RAG Server</td></tr>\n",
    "<tr><td><b>Deploy VSS</b></td><td>Clone VSS, deploy NIMs and VLM</td></tr>\n",
    "<tr><td><b>Deploy Continuous Ingestion</b></td><td>Kafka, MinIO, Consumer</td></tr>\n",
    "<tr><td><b>Testing</b></td><td>Upload documents & videos, query RAG</td></tr>\n",
    "<tr><td><b>Clean Up</b></td><td>Stop services, clean data</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- **RAG Blueprint**: [NVIDIA RAG Documentation](https://github.com/NVIDIA-AI-Blueprints/rag/blob/develop/docs/deploy-docker-self-hosted.md)\n",
    "- **VSS**: [Video Search & Summarization Documentation](https://docs.nvidia.com/vss/latest/index.html)\n",
    "- **NIM**: [NVIDIA NIM Documentation](https://docs.nvidia.com/nim/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Clone the repository, configure API keys, and load helper functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone Repository\n",
    "\n",
    "Clone the RAG Blueprint repo to `~/rag`. This includes the consumer source code, deploy configs, and sample test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys, os\n",
    "\n",
    "RAG_REPO_DIR = os.path.expanduser(\"~/rag\")\n",
    "RAG_REPO_URL = \"https://github.com/NVIDIA-AI-Blueprints/rag.git\"\n",
    "\n",
    "# Clone from correct branch (skip if already exists)\n",
    "if not os.path.exists(RAG_REPO_DIR):\n",
    "    subprocess.run(f\"git clone {RAG_REPO_URL} {RAG_REPO_DIR}\", shell=True, check=True)\n",
    "else:\n",
    "    print(f\"[OK] RAG repo already exists: {RAG_REPO_DIR}\")\n",
    "subprocess.run(\"git lfs pull\", shell=True, cwd=RAG_REPO_DIR, check=True)\n",
    "\n",
    "# Verify\n",
    "for path in [\"deploy/compose\", \"examples/rag_event_ingest/kafka_consumer\", \"examples/rag_event_ingest/data\"]:\n",
    "    status = \"[OK]\" if os.path.exists(os.path.join(RAG_REPO_DIR, path)) else \"[MISSING]\"\n",
    "    print(f\"  {status} {path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def check_install_system_pkg(cmd: str, install_cmd: str):\n",
    "    if shutil.which(cmd):\n",
    "        print(f\"  [OK] {cmd} found\")\n",
    "        return True\n",
    "    print(f\"  [INSTALLING] {cmd}...\")\n",
    "    result = subprocess.run(install_cmd, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"  [OK] {cmd} installed\")\n",
    "        return True\n",
    "    print(f\"  [ERROR] Failed to install {cmd}. Please install manually: {install_cmd}\")\n",
    "    return False\n",
    "\n",
    "check_install_system_pkg(\"git\", \"sudo apt-get update && sudo apt-get install -y git\")\n",
    "check_install_system_pkg(\"git-lfs\", \"sudo apt-get install -y git-lfs && git lfs install\")\n",
    "\n",
    "# Install Python packages\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"minio\", \"aiohttp\", \"requests\", \"python-dotenv\", \"pyyaml\"])\n",
    "print(\"[OK] Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set API Keys\n",
    "\n",
    "Configure NGC and HuggingFace API keys for NIM deployments and model downloads.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "def set_api_key(env_var: str, prompt: str, required: bool = True):\n",
    "    if os.environ.get(env_var):\n",
    "        print(f\"  [OK] {env_var} already set ({os.environ[env_var][:10]}...)\")\n",
    "        return True\n",
    "    key = getpass.getpass(prompt)\n",
    "    if key:\n",
    "        os.environ[env_var] = key\n",
    "        print(f\"  [OK] {env_var} set\")\n",
    "        return True\n",
    "    if required:\n",
    "        print(f\"  [ERROR] {env_var} is required\")\n",
    "        return False\n",
    "    print(f\"  [SKIP] {env_var} (optional)\")\n",
    "    return True\n",
    "\n",
    "set_api_key(\"NGC_API_KEY\", \"Enter NGC_API_KEY (starts with 'nvapi-'): \", required=True)\n",
    "set_api_key(\"HF_TOKEN\", \"Enter HF_TOKEN (optional, press Enter to skip): \", required=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper Functions\n",
    "\n",
    "Shared utilities for deployment, file upload, status checks, and RAG queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "import sys\n",
    "!{sys.executable} -m pip install -q minio aiohttp requests python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, re, subprocess, time, socket, asyncio\n",
    "import aiohttp, requests\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "try:\n",
    "    from minio import Minio\n",
    "    from minio.error import S3Error\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"minio\"])\n",
    "    from minio import Minio\n",
    "    from minio.error import S3Error\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Paths relative to RAG repo root\n",
    "RAG_REPO_DIR = os.path.expanduser(\"~/rag\")\n",
    "EXAMPLE_DIR = os.path.join(RAG_REPO_DIR, \"examples/rag_event_ingest\")\n",
    "AIDP_COMPOSE_FILE = os.path.join(EXAMPLE_DIR, \"deploy/docker-compose.yaml\")\n",
    "DATA_DIR = os.path.join(EXAMPLE_DIR, \"data\")\n",
    "RAG_SERVER_URL = \"http://localhost:8081\"\n",
    "INGESTOR_URL = \"http://localhost:8082\"\n",
    "\n",
    "VSS_DIR = os.path.expanduser(\"~/video-search-and-summarization\")\n",
    "VSS_UI_PORT = 9110\n",
    "VSS_API_PORT = 8110\n",
    "VSS_LLM_PORT = 8107\n",
    "VSS_EMBED_PORT = 8106\n",
    "VSS_RERANK_PORT = 8105\n",
    "LOCAL_NIM_CACHE = os.path.expanduser(\"~/.cache/nim\")\n",
    "\n",
    "MINIO_ENDPOINT = \"localhost:9201\"\n",
    "MINIO_ACCESS_KEY = \"minioadmin\"\n",
    "MINIO_SECRET_KEY = \"minioadmin\"\n",
    "MINIO_BUCKET = \"aidp-bucket\"\n",
    "MINIO_COLLECTION = \"aidp_bucket\"\n",
    "MINIO_CONSOLE_PORT = 9211\n",
    "\n",
    "# =============================================================================\n",
    "# SHARED UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "def run_command(cmd: str, capture: bool = False) -> Optional[str]:\n",
    "    \"\"\"Execute a shell command and print it.\"\"\"\n",
    "    print(f\"$ {cmd}\")\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=capture, text=True)\n",
    "    return result.stdout if capture else None\n",
    "\n",
    "def get_host_ip() -> str:\n",
    "    \"\"\"Get host IP address for external access URLs.\"\"\"\n",
    "    try:\n",
    "        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "        s.connect((\"8.8.8.8\", 80))\n",
    "        ip = s.getsockname()[0]\n",
    "        s.close()\n",
    "        return ip\n",
    "    except OSError:\n",
    "        return \"localhost\"\n",
    "\n",
    "def get_minio_client() -> Minio:\n",
    "    \"\"\"Create MinIO client for AIDP bucket operations.\"\"\"\n",
    "    return Minio(MINIO_ENDPOINT, access_key=MINIO_ACCESS_KEY, secret_key=MINIO_SECRET_KEY, secure=False)\n",
    "\n",
    "def upload_file(local_path: str, object_name: Optional[str] = None) -> bool:\n",
    "    \"\"\"Upload a local file to MinIO AIDP bucket.\"\"\"\n",
    "    if not os.path.exists(local_path):\n",
    "        print(f\"[ERROR] File not found: {local_path}\")\n",
    "        return False\n",
    "    obj = object_name or os.path.basename(local_path)\n",
    "    try:\n",
    "        client = get_minio_client()\n",
    "        if not client.bucket_exists(MINIO_BUCKET):\n",
    "            client.make_bucket(MINIO_BUCKET)\n",
    "        client.fput_object(MINIO_BUCKET, obj, local_path)\n",
    "        print(f\"[OK] Uploaded: {obj}\")\n",
    "        return True\n",
    "    except S3Error as e:\n",
    "        print(f\"[ERROR] {e}\")\n",
    "        return False\n",
    "\n",
    "def verify_file_in_storage(object_name: str, bucket: str = MINIO_BUCKET) -> bool:\n",
    "    \"\"\"Check if a file exists in MinIO bucket and print verification status.\"\"\"\n",
    "    try:\n",
    "        client = get_minio_client()\n",
    "        stat = client.stat_object(bucket, object_name)\n",
    "        print(f\"[OK] File verified in storage:\")\n",
    "        print(f\"  Bucket:   {bucket}\")\n",
    "        print(f\"  Object:   {object_name}\")\n",
    "        print(f\"  Size:     {stat.size:,} bytes\")\n",
    "        print(f\"  Modified: {stat.last_modified}\")\n",
    "        return True\n",
    "    except S3Error as e:\n",
    "        print(f\"[ERROR] File not found in storage: {object_name}\")\n",
    "        print(f\"  Error: {e}\")\n",
    "        return False\n",
    "\n",
    "def get_consumer_logs(lines: int = 30) -> None:\n",
    "    \"\"\"Show recent Kafka consumer logs.\"\"\"\n",
    "    run_command(f\"docker logs kafka-consumer --tail {lines}\")\n",
    "\n",
    "async def query_rag(question: str, collection: str = None) -> Optional[str]:\n",
    "    \"\"\"Query RAG system and print the answer.\"\"\"\n",
    "    coll = collection or MINIO_COLLECTION\n",
    "    print(f\"Q: {question}\\nCollection: {coll}\\n\" + \"-\" * 40)\n",
    "\n",
    "    payload = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}],\n",
    "        \"use_knowledge_base\": True,\n",
    "        \"collection_name\": coll,\n",
    "    }\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.post(\n",
    "                f\"{RAG_SERVER_URL}/generate\", json=payload,\n",
    "                timeout=aiohttp.ClientTimeout(total=120),\n",
    "            ) as resp:\n",
    "                text = await resp.text()\n",
    "                # Parse SSE response: extract content from each \"data: {...}\" line\n",
    "                chunks = []\n",
    "                for line in text.split(\"\\n\"):\n",
    "                    if not line.startswith(\"data: \") or line[6:] == \"[DONE]\":\n",
    "                        continue\n",
    "                    try:\n",
    "                        msg = json.loads(line[6:]).get(\"choices\", [{}])[0].get(\"message\", {})\n",
    "                        if msg.get(\"content\"):\n",
    "                            chunks.append(msg[\"content\"])\n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "                answer = \"\".join(chunks)\n",
    "                print(f\"Answer: {answer}\")\n",
    "                return answer\n",
    "    except aiohttp.ClientError as e:\n",
    "        print(f\"[ERROR] {e}\")\n",
    "        return None\n",
    "\n",
    "print(f\"[OK] Helpers loaded | Host IP: {get_host_ip()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy NVIDIA RAG\n",
    "\n",
    "Deploy the NVIDIA RAG: NIMs (LLM, Embedding, Reranker), Milvus vector database, Ingestor server, and RAG server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngc_key = os.environ.get(\"NGC_API_KEY\")\n",
    "if not ngc_key:\n",
    "    raise RuntimeError(\"NGC_API_KEY not set! Run the API keys cell first.\")\n",
    "\n",
    "os.chdir(RAG_REPO_DIR)\n",
    "\n",
    "# Set env vars needed by docker compose\n",
    "os.environ[\"NGC_API_KEY\"] = ngc_key\n",
    "os.environ[\"USERID\"] = f\"{os.getuid()}:{os.getgid()}\"\n",
    "os.environ[\"COLLECTION_NAME\"] = MINIO_COLLECTION\n",
    "\n",
    "# Load RAG .env defaults (MODEL_DIRECTORY, etc.)\n",
    "from dotenv import load_dotenv\n",
    "env_file = os.path.join(RAG_REPO_DIR, \"deploy/compose/.env\")\n",
    "if os.path.exists(env_file):\n",
    "    load_dotenv(env_file, override=False)\n",
    "\n",
    "# Login to nvcr.io\n",
    "subprocess.run(f\"echo {ngc_key} | docker login nvcr.io -u '$oauthtoken' --password-stdin\",\n",
    "               shell=True, capture_output=True, text=True, executable=\"/bin/bash\")\n",
    "\n",
    "# Deploy components\n",
    "for label, compose_file in [\n",
    "    (\"NIMs\",      \"deploy/compose/nims.yaml\"),\n",
    "    (\"Vector DB\", \"deploy/compose/vectordb.yaml\"),\n",
    "]:\n",
    "    print(f\"Deploying {label}...\")\n",
    "    run_command(f\"docker compose -f {compose_file} up -d\")\n",
    "\n",
    "print(\"Waiting 30s for Milvus...\")\n",
    "time.sleep(30)\n",
    "\n",
    "for label, compose_file in [\n",
    "    (\"Ingestor\", \"deploy/compose/docker-compose-ingestor-server.yaml\"),\n",
    "    (\"RAG Server\", \"deploy/compose/docker-compose-rag-server.yaml\"),\n",
    "]:\n",
    "    print(f\"Deploying {label}...\")\n",
    "    run_command(f\"docker compose -f {compose_file} up -d\")\n",
    "\n",
    "ip = get_host_ip()\n",
    "print(f\"\\nRAG deployed: http://{ip}:8081 (server) | http://{ip}:8082 (ingestor) | http://{ip}:8090 (UI)\")\n",
    "print(f\"COLLECTION_NAME: {MINIO_COLLECTION}\")\n",
    "print(\"Wait 2-5 minutes for NIMs to load models, then run the status check cell.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify RAG services are healthy. Wait 2-5 minutes for NIMs to load models.\n",
    "\n",
    "The deployment status should be:\n",
    "```\n",
    "NAMES                            STATUS\n",
    "rag-frontend                     Up About a minute\n",
    "rag-server                       Up About a minute\n",
    "ingestor-server                  Up About a minute\n",
    "milvus-standalone                Up 2 minutes (healthy)\n",
    "milvus-etcd                      Up 2 minutes (healthy)\n",
    "milvus-minio                     Up 2 minutes (healthy)\n",
    "nim-llm-ms                       Up 2 minutes (healthy)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check service status and print access URLs\n",
    "print(\"Wait 2-5 minutes for services to become healthy.\")\n",
    "print(\"Run this cell again after waiting.\\n\")\n",
    "\n",
    "ip = get_host_ip()\n",
    "for name, port, path in [\n",
    "    (\"RAG Server\", 8081, \"/health\"), (\"Ingestor\", 8082, \"/health\"),\n",
    "    (\"Frontend\", 8090, \"/\"), (\"Milvus\", 19530, \"/v1/vector/collections\"),\n",
    "]:\n",
    "    try:\n",
    "        s = \"[OK]\" if requests.get(f\"http://localhost:{port}{path}\", timeout=10).status_code == 200 else \"[WARN]\"\n",
    "    except requests.ConnectionError:\n",
    "        s = \"[DOWN]\"\n",
    "    except requests.Timeout:\n",
    "        s = \"[TIMEOUT]\"\n",
    "    print(f\"  {s} {name}: http://{ip}:{port}\")\n",
    "run_command(\"docker ps --format 'table {{.Names}}\\t{{.Status}}' | grep -E '(rag|milvus|ingestor|nim|NAMES)'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy NVIDIA VSS\n",
    "\n",
    "Deploy the NVIDIA VSS: NIMs (LLM, Embedding, Reranker) and VLM for video analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VSS deployment configuration\n",
    "VSS_REPO_URL = \"https://github.com/NVIDIA-AI-Blueprints/video-search-and-summarization.git\"\n",
    "VSS_TAG = \"2.4.1\"  # VSS Blueprint version (must match VIA_IMAGE tag)\n",
    "VSS_GPU_DEVICE = 4       # GPU for NIMs (LLM, Embedding, Reranker)\n",
    "VSS_VLM_GPU_DEVICE = 5   # GPU for VLM (via-server with Cosmos-Reason2)\n",
    "\n",
    "NIM_IMAGES = {\n",
    "    \"vss-llm\":       (\"nvcr.io/nim/meta/llama-3.1-8b-instruct:1.12.0\",      VSS_LLM_PORT),\n",
    "    \"vss-embedding\": (\"nvcr.io/nim/nvidia/llama-3.2-nv-embedqa-1b-v2:1.9.0\", VSS_EMBED_PORT),\n",
    "    \"vss-reranker\":  (\"nvcr.io/nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:1.7.0\", VSS_RERANK_PORT),\n",
    "}\n",
    "\n",
    "ngc_key = os.environ.get(\"NGC_API_KEY\", \"\")\n",
    "hf_token = os.environ.get(\"HF_TOKEN\", \"\")\n",
    "if not ngc_key:\n",
    "    raise RuntimeError(\"NGC_API_KEY not set!\")\n",
    "\n",
    "# Docker login\n",
    "subprocess.run(f\"echo {ngc_key} | docker login nvcr.io -u '$oauthtoken' --password-stdin\",\n",
    "               shell=True, capture_output=True, text=True, executable=\"/bin/bash\")\n",
    "\n",
    "# Clone VSS repo with correct release tag\n",
    "if not os.path.exists(VSS_DIR):\n",
    "    print(f\"Cloning {VSS_REPO_URL} (tag: {VSS_TAG})...\")\n",
    "    subprocess.run(f\"git clone --branch {VSS_TAG} --depth 1 {VSS_REPO_URL} {VSS_DIR}\", shell=True)\n",
    "else:\n",
    "    print(f\"[OK] VSS repo exists: {VSS_DIR}\")\n",
    "\n",
    "# Deploy NIM containers (all on same GPU)\n",
    "os.makedirs(LOCAL_NIM_CACHE, exist_ok=True)\n",
    "for name, (image, port) in NIM_IMAGES.items():\n",
    "    subprocess.run(f\"docker rm -f {name} 2>/dev/null\", shell=True, capture_output=True)\n",
    "    cmd = f\"\"\"docker run -d --name {name} \\\n",
    "        -u $(id -u) --gpus '\"device={VSS_GPU_DEVICE}\"' --shm-size=16GB \\\n",
    "        --network nvidia-rag -e NGC_API_KEY={ngc_key} \\\n",
    "        -v \"{LOCAL_NIM_CACHE}:/opt/nim/.cache\" \\\n",
    "        -p {port}:8000 -e NIM_LOW_MEMORY_MODE=1 -e NIM_RELAX_MEM_CONSTRAINTS=1 \\\n",
    "        {image}\"\"\"\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True, executable=\"/bin/bash\")\n",
    "    status = \"[OK]\" if result.returncode == 0 else \"[ERROR]\"\n",
    "    print(f\"  {status} {name} -> port {port}\")\n",
    "\n",
    "# Deploy VSS application (VLM on separate GPU)\n",
    "vss_deploy_dir = f\"{VSS_DIR}/deploy/docker/local_deployment_single_gpu\"\n",
    "env_content = f\"\"\"NGC_API_KEY={ngc_key}\n",
    "HF_TOKEN={hf_token}\n",
    "VIA_IMAGE=nvcr.io/nvidia/blueprint/vss-engine:2.4.1\n",
    "FRONTEND_PORT={VSS_UI_PORT}\n",
    "BACKEND_PORT={VSS_API_PORT}\n",
    "MILVUS_DB_HTTP_PORT=19091\n",
    "MILVUS_DB_GRPC_PORT=29530\n",
    "MINIO_PORT=9002\n",
    "MINIO_WEBUI_PORT=9003\n",
    "GRAPH_DB_USERNAME=neo4j\n",
    "GRAPH_DB_PASSWORD=password\n",
    "ARANGO_DB_USERNAME=arangodb\n",
    "ARANGO_DB_PASSWORD=password\n",
    "CA_RAG_CONFIG=./config.yaml\n",
    "GUARDRAILS_CONFIG=./guardrails\n",
    "NVIDIA_VISIBLE_DEVICES={VSS_VLM_GPU_DEVICE}\n",
    "VLM_MODEL_TO_USE=cosmos-reason2\n",
    "MODEL_PATH=git:https://huggingface.co/nvidia/Cosmos-Reason2-8B\n",
    "VLLM_GPU_MEMORY_UTILIZATION=0.4\n",
    "VLM_MAX_MODEL_LEN=20480\n",
    "DISABLE_GUARDRAILS=true\n",
    "DISABLE_CV_PIPELINE=true\n",
    "ENABLE_AUDIO=false\n",
    "\"\"\"\n",
    "with open(f\"{vss_deploy_dir}/.env\", \"w\") as f:\n",
    "    f.write(env_content)\n",
    "\n",
    "# Patch config.yaml to use our NIM ports\n",
    "config_file = f\"{vss_deploy_dir}/config.yaml\"\n",
    "if os.path.exists(config_file):\n",
    "    cfg = open(config_file).read()\n",
    "    cfg = re.sub(r\":8007/v1\", f\":{VSS_LLM_PORT}/v1\", cfg)\n",
    "    cfg = re.sub(r\":8006/v1\", f\":{VSS_EMBED_PORT}/v1\", cfg)\n",
    "    cfg = re.sub(r\":8005/v1\", f\":{VSS_RERANK_PORT}/v1\", cfg)\n",
    "    open(config_file, \"w\").write(cfg)\n",
    "\n",
    "cmd = f\"cd {vss_deploy_dir} && set -a && source .env && set +a && docker compose up -d\"\n",
    "subprocess.run(cmd, shell=True, capture_output=True, text=True, executable=\"/bin/bash\")\n",
    "\n",
    "ip = get_host_ip()\n",
    "print(f\"\\nVSS deployed: http://{ip}:{VSS_UI_PORT} (UI) | http://{ip}:{VSS_API_PORT} (API)\")\n",
    "print(\"Wait 2-5 minutes for NIMs to load models, then run the status check cell.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify VSS services are healthy. Wait 2-5 minutes for NIMs to load models.\n",
    "\n",
    "The deployment status should be:\n",
    "```\n",
    "NAMES                                             STATUS\n",
    "local_deployment_single_gpu-via-server-1          Up About a minute\n",
    "local_deployment_single_gpu-elasticsearch-1       Up About a minute\n",
    "local_deployment_single_gpu-graph-db-1            Up About a minute\n",
    "local_deployment_single_gpu-minio-1               Up About a minute\n",
    "local_deployment_single_gpu-arango-db-1           Up About a minute\n",
    "local_deployment_single_gpu-milvus-standalone-1   Up About a minute (healthy)\n",
    "vss-reranker                                      Up About a minute\n",
    "vss-embedding                                     Up About a minute\n",
    "vss-llm                                           Up About a minute\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check service status and print access URLs\n",
    "ip = get_host_ip()\n",
    "for name, port, path in [\n",
    "    (\"VSS UI\", VSS_UI_PORT, \"/\"), (\"VSS API\", VSS_API_PORT, \"/\"),\n",
    "    (\"LLM NIM\", VSS_LLM_PORT, \"/v1/health/ready\"),\n",
    "    (\"Embedding\", VSS_EMBED_PORT, \"/v1/health/ready\"),\n",
    "    (\"Reranker\", VSS_RERANK_PORT, \"/v1/health/ready\"),\n",
    "]:\n",
    "    try:\n",
    "        requests.get(f\"http://localhost:{port}{path}\", timeout=10)\n",
    "        s = \"[OK]\"\n",
    "    except requests.ConnectionError:\n",
    "        s = \"[DOWN]\"\n",
    "    except requests.Timeout:\n",
    "        s = \"[TIMEOUT]\"\n",
    "    print(f\"  {s} {name}: http://{ip}:{port}\")\n",
    "run_command(\"docker ps --format 'table {{.Names}}\\t{{.Status}}' | grep -E '(vss|via|local_deployment|NAMES)'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Continuous Ingestion from emulated object storage\n",
    "\n",
    "Deploy the Continuous Ingestion: Kafka message broker, MinIO object storage, and Kafka consumer for automated ingestion.\n",
    "\n",
    "## 1. Configure Video Analysis Prompts\n",
    "\n",
    "Customize the prompts used by the Kafka consumer when processing videos through VSS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumer prompts for video analysis - customize these for your video content\n",
    "# These are passed to the Kafka consumer which sends them to VSS for video summarization\n",
    "\n",
    "CONSUMER_VSS_PROMPT = \"\"\"Analyze this sports video. TIMESTAMP FORMAT: Convert seconds to MM:SS (40s=00:40, 80s=01:20, 150s=02:30, 200s=03:20). \\\n",
    "Describe: key plays, scoring, turnovers, big gains, defensive stops, celebrations.\"\"\"\n",
    "\n",
    "CONSUMER_VSS_SYSTEM_PROMPT = \"\"\"You are a sports broadcaster. CRITICAL: Convert all timestamps from seconds to MM:SS format. \\\n",
    "Examples: 40 seconds = 00:40, 90 seconds = 01:30, 200 seconds = 03:20, 350 seconds = 05:50. Focus on action, field position, execution, and game momentum.\"\"\"\n",
    "\n",
    "CONSUMER_VSS_CAPTION_SUMMARIZATION_PROMPT = \"\"\"Format: [MM:SS] Play description. CONVERT seconds to MM:SS (40s=00:40, 80s=01:20, 150s=02:30). \\\n",
    "Describe: what happened, how it was executed, the result. Be vivid like a TV broadcast.\"\"\"\n",
    "\n",
    "CONSUMER_VSS_SUMMARY_AGGREGATION_PROMPT = \"\"\"Create game summary with MM:SS timestamps. CONVERT all times: 40s=00:40, 80s=01:20, 200s=03:20, 350s=05:50. \\\n",
    "Highlight scoring plays, turnovers, momentum shifts, spectacular plays. Write like a highlight reel narrator - vivid and exciting.\"\"\"\n",
    "\n",
    "print(\"Consumer VSS prompts configured:\")\n",
    "print(f\"  VSS_PROMPT: {len(CONSUMER_VSS_PROMPT)} chars\")\n",
    "print(f\"  VSS_SYSTEM_PROMPT: {len(CONSUMER_VSS_SYSTEM_PROMPT)} chars\")\n",
    "print(f\"  VSS_CAPTION_SUMMARIZATION_PROMPT: {len(CONSUMER_VSS_CAPTION_SUMMARIZATION_PROMPT)} chars\")\n",
    "print(f\"  VSS_SUMMARY_AGGREGATION_PROMPT: {len(CONSUMER_VSS_SUMMARY_AGGREGATION_PROMPT)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deploy Services\n",
    "\n",
    "Deploy Kafka, MinIO, and the Kafka consumer with custom prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify prerequisites\n",
    "net_check = subprocess.run(\"docker network inspect nvidia-rag\", shell=True, capture_output=True)\n",
    "if net_check.returncode != 0:\n",
    "    raise RuntimeError(\"nvidia-rag network not found. Deploy RAG first.\")\n",
    "\n",
    "ngc_key = os.environ.get(\"NGC_API_KEY\", \"\")\n",
    "if not ngc_key:\n",
    "    raise RuntimeError(\"NGC_API_KEY not set!\")\n",
    "\n",
    "host_ip = get_host_ip()\n",
    "\n",
    "# Set environment variables for docker compose (including custom prompts)\n",
    "os.environ[\"VSS_SERVER_URL\"] = f\"http://{host_ip}:{VSS_API_PORT}\"\n",
    "os.environ[\"VSS_PROMPT\"] = CONSUMER_VSS_PROMPT\n",
    "os.environ[\"VSS_SYSTEM_PROMPT\"] = CONSUMER_VSS_SYSTEM_PROMPT\n",
    "os.environ[\"VSS_CAPTION_SUMMARIZATION_PROMPT\"] = CONSUMER_VSS_CAPTION_SUMMARIZATION_PROMPT\n",
    "os.environ[\"VSS_SUMMARY_AGGREGATION_PROMPT\"] = CONSUMER_VSS_SUMMARY_AGGREGATION_PROMPT\n",
    "\n",
    "# Login + pull + build\n",
    "subprocess.run(f\"echo {ngc_key} | docker login nvcr.io -u '$oauthtoken' --password-stdin\",\n",
    "               shell=True, capture_output=True, text=True, executable=\"/bin/bash\")\n",
    "\n",
    "compose = f\"docker compose -f {AIDP_COMPOSE_FILE}\"\n",
    "subprocess.run(f\"{compose} pull --ignore-pull-failures\", shell=True, capture_output=True, text=True, executable=\"/bin/bash\")\n",
    "subprocess.run(f\"{compose} up -d --build\", shell=True, capture_output=True, text=True, executable=\"/bin/bash\")\n",
    "\n",
    "print(f\"Continuous Ingestion deployed:\")\n",
    "print(f\"  Kafka UI:      http://{host_ip}:8080\")\n",
    "print(f\"  MinIO Console: http://{host_ip}:{MINIO_CONSOLE_PORT}\")\n",
    "print(f\"  Credentials:   minioadmin / minioadmin\")\n",
    "print(f\"  Custom prompts: âœ“ passed to consumer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify continuous ingestion services are running.\n",
    "\n",
    "The deployment status should be:\n",
    "```\n",
    "NAMES                            STATUS\n",
    "kafka-consumer                   Up About a minute\n",
    "aidp-kafka-ui                    Up About a minute\n",
    "aidp-minio-mc                    Up About a minute\n",
    "aidp-minio                       Up About a minute (healthy)\n",
    "kafka                            Up About a minute (healthy)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check service status and print access URLs\n",
    "ip = get_host_ip()\n",
    "print(f\"  Kafka UI:      http://{ip}:8080\")\n",
    "print(f\"  MinIO Console: http://{ip}:{MINIO_CONSOLE_PORT}\")\n",
    "run_command(\"docker ps --format 'table {{.Names}}\\t{{.Status}}' | grep -E '(kafka|minio|NAMES)'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Test the deployment by uploading documents and videos, then querying via RAG.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document Upload\n",
    "\n",
    "Upload a PDF document to MinIO, which triggers automatic ingestion via Kafka consumer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Upload to Storage\n",
    "\n",
    "Upload the document to MinIO object storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents are included in the repo under examples/rag_event_ingest/data/\n",
    "pdf_path = os.path.join(DATA_DIR, \"documents\", \"Seahawks-Patriots in Super Bowl LX_ What We Learned from Seattle's 29-13 win.pdf\")\n",
    "upload_file(pdf_path, \"Seahawks-Patriots_SuperBowl_LX_Analysis.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Verify Document Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check consumer logs to verify document processing status.\n",
    "\n",
    "The logs should show the document being picked up and successfully ingested:\n",
    "```\n",
    "services.document_indexer - INFO - Task ...: PENDING (0s)\n",
    "services.document_indexer - INFO - Task ...: PENDING (5s)\n",
    "handlers.base - INFO - [DocumentHandler] âœ“ Seahawks-Patriots_SuperBowl_LX_Analysis.pdf â†’ SUCCESS\n",
    "consumer - INFO - âœ“ SUMMARY: Seahawks-Patriots_SuperBowl_LX_Analysis.pdf | Collection: aidp_bucket | Duration: 12.76s | Status: SUCCESS\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify file landed in object storage\n",
    "verify_file_in_storage(\"Seahawks-Patriots_SuperBowl_LX_Analysis.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Verify Document Ingestion\n",
    "\n",
    "Check consumer logs to verify document processing status.\n",
    "\n",
    "The logs should show the document being picked up and successfully ingested:\n",
    "```\n",
    "services.document_indexer - INFO - Task ...: PENDING (0s)\n",
    "services.document_indexer - INFO - Task ...: PENDING (5s)\n",
    "handlers.base - INFO - [DocumentHandler] âœ“ Seahawks-Patriots_SuperBowl_LX_Analysis.pdf â†’ SUCCESS\n",
    "consumer - INFO - âœ“ SUMMARY: Seahawks-Patriots_SuperBowl_LX_Analysis.pdf | Collection: aidp_bucket | Duration: 12.76s | Status: SUCCESS\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check consumer logs for ingestion status\n",
    "print(\"Waiting for document processing...\")\n",
    "get_consumer_logs(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Query Document via RAG\n",
    "\n",
    "You can query the ingested document either **programmatically** below or via the **RAG Frontend UI**.\n",
    "\n",
    "> **ðŸ’¡ RAG Frontend**: Open `http://<host-ip>:8090` in your browser for an interactive Q&A interface.\n",
    "> Make sure to select the collection **`aidp_bucket`** in the UI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the document\n",
    "await query_rag(\"What was the final score and who won Super Bowl LX?\", MINIO_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask another question about the document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query about key takeaways\n",
    "await query_rag(\"What were the key lessons learned from Seattle's victory in Super Bowl LX?\", MINIO_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Video Upload\n",
    "\n",
    "Upload a video to MinIO, which triggers automatic ingestion via Kafka consumer â†’ VSS for video analysis â†’ RAG for indexing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Upload to Storage\n",
    "\n",
    "Upload the video to MinIO object storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample videos are included in the repo under examples/rag_event_ingest/data/\n",
    "video_path = os.path.join(DATA_DIR, \"videos\", \"Seattle Seahawks vs New England Patriots - Super Bowl LX Game Highlights.mp4\")\n",
    "upload_file(video_path)\n",
    "\n",
    "print(\"\\nVideo processing takes longer than documents. Check consumer logs for progress.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Verify Video Ingestion\n",
    "\n",
    "Check consumer logs to verify video processing status.\n",
    "\n",
    "The logs should show the video being picked up and processed by VSS:\n",
    "```\n",
    "handlers.video - INFO - [VideoHandler] Processing video: Seattle Seahawks vs New England Patriots - Super Bowl LX Game Highlights.mp4\n",
    "services.video_analyzer - INFO - Submitting video to VSS...\n",
    "services.video_analyzer - INFO - VSS processing complete\n",
    "handlers.base - INFO - [VideoHandler] âœ“ Seattle Seahawks...mp4 â†’ SUCCESS\n",
    "consumer - INFO - âœ“ SUMMARY: Seattle Seahawks...mp4 | Collection: aidp_bucket | Duration: ~120s | Status: SUCCESS\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify video landed in object storage\n",
    "video_filename = os.path.basename(video_path)\n",
    "verify_file_in_storage(video_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Verify Video Ingestion\n",
    "\n",
    "Check consumer logs to verify video processing status.\n",
    "\n",
    "The logs should show the video being picked up and processed by VSS:\n",
    "```\n",
    "handlers.video - INFO - [VideoHandler] Processing video: Seattle Seahawks vs New England Patriots - Super Bowl LX Game Highlights.mp4\n",
    "services.video_analyzer - INFO - Submitting video to VSS...\n",
    "services.video_analyzer - INFO - VSS processing complete\n",
    "handlers.base - INFO - [VideoHandler] âœ“ Seattle Seahawks...mp4 â†’ SUCCESS\n",
    "consumer - INFO - âœ“ SUMMARY: Seattle Seahawks...mp4 | Collection: aidp_bucket | Duration: ~120s | Status: SUCCESS\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check consumer logs for ingestion status\n",
    "print(\"Waiting for video processing...\")\n",
    "get_consumer_logs(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Query Video via RAG\n",
    "\n",
    "Query the video content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query about the video content\n",
    "await query_rag(\"Summarize the video content\", MINIO_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query about a specific time range in the video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query about specific time range\n",
    "await query_rag(\"What happened between 15:00 and 20:00?\", MINIO_COLLECTION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional query: analyze key defensive plays and turnovers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defensive Analysis\n",
    "await query_rag(\"Describe the key defensive plays and turnovers that impacted the game outcome.\", MINIO_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional query: identify critical momentum-changing plays in the second half.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum Shifts\n",
    "await query_rag(\"What were the critical momentum-changing plays in the second half of the game?\", MINIO_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up\n",
    "\n",
    "Stop all services and clean up ingested data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Stop RAG Deployment\n",
    "\n",
    "Stop all RAG services (NIMs, Milvus, Ingestor, RAG server).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(RAG_REPO_DIR)\n",
    "for f in [\n",
    "    \"deploy/compose/docker-compose-rag-server.yaml\",\n",
    "    \"deploy/compose/docker-compose-ingestor-server.yaml\",\n",
    "    \"deploy/compose/vectordb.yaml\",\n",
    "    \"deploy/compose/nims.yaml\",\n",
    "]:\n",
    "    run_command(f\"docker compose -f {f} down\")\n",
    "print(\"[OK] RAG stopped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stop VSS Deployment\n",
    "\n",
    "Stop all VSS services (NIMs, VLM, via-server).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vss_deploy_dir = f\"{VSS_DIR}/deploy/docker/local_deployment_single_gpu\"\n",
    "if os.path.exists(vss_deploy_dir):\n",
    "    subprocess.run(f\"cd {vss_deploy_dir} && set -a && source .env 2>/dev/null && set +a && docker compose down\",\n",
    "                   shell=True, executable=\"/bin/bash\", capture_output=True)\n",
    "for name in [\"vss-llm\", \"vss-embedding\", \"vss-reranker\"]:\n",
    "    subprocess.run(f\"docker rm -f {name} 2>/dev/null\", shell=True, capture_output=True)\n",
    "print(\"[OK] VSS stopped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stop Continuous ingestion Deployment\n",
    "\n",
    "Stop Continuous ingestion services (Kafka, MinIO, Consumer).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_command(f\"docker compose -f {AIDP_COMPOSE_FILE} down\")\n",
    "print(\"[OK] Continuous ingestion stopped\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
