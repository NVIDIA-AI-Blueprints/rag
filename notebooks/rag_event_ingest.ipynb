{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video/Document Continuous Ingestion from Object Storage\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook demonstrates an **automated document and video ingestion pipeline** that:\n",
    "\n",
    "1. Monitors object storage (MinIO) for new uploads via Kafka events\n",
    "2. Routes files to appropriate AI services based on file type\n",
    "3. Indexes documents using NVIDIA RAG Blueprint for semantic search\n",
    "4. Analyzes videos using NVIDIA VSS (Video Search & Summarization)\n",
    "5. Enables RAG Agent for semantic search and contextual Q&A over all ingested content\n",
    "\n",
    "## What Gets Deployed\n",
    "\n",
    "1. **RAG Stack** - Document indexing, vector search, and AI-powered Q&A (NIMs, Milvus, Ingestor)\n",
    "2. **VSS Stack** - Video understanding and summarization (VLM, LLM NIMs, VSS Engine)\n",
    "3. **AIDP Stack** - Event-driven ingestion pipeline (Kafka, MinIO, Consumer)\n",
    "\n",
    "> **Note**: This notebook is part of the NVIDIA RAG Blueprint. All source code, sample data,\n",
    "> and deployment configs are included in `examples/rag_event_ingest/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### Hardware\n",
    "- **GPU**: 2+ NVIDIA GPUs with 24GB+ VRAM each\n",
    "- **RAM**: 64GB+ system memory\n",
    "- **Disk**: 200GB+ free space\n",
    "\n",
    "### Software (must be pre-installed)\n",
    "- Ubuntu 22.04 or later\n",
    "- Docker 24.0+ with Docker Compose v2\n",
    "- NVIDIA Driver 570+\n",
    "- NVIDIA Container Toolkit\n",
    "- Git and Git LFS\n",
    "\n",
    "### API Keys\n",
    "\n",
    "| Key | Purpose | How to Get |\n",
    "|-----|---------|------------|\n",
    "| `NGC_API_KEY` | Docker login, NIM deployments | [NGC Portal](https://org.ngc.nvidia.com/setup/api-keys) |\n",
    "| `HF_TOKEN` | Download VSS models (optional) | [HuggingFace Tokens](https://huggingface.co/settings/tokens) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "| Section | Description |\n",
    "|---------|-------------|\n",
    "| **Setup** | Clone repo, install deps, set API keys, load helpers |\n",
    "| **Deploy RAG** | NIMs, Vector DB, Ingestor, RAG Server |\n",
    "| **Deploy VSS** | Clone VSS, deploy NIMs and VLM |\n",
    "| **Deploy AIDP** | Kafka, MinIO, Consumer |\n",
    "| **Testing** | Upload documents & videos, query RAG |\n",
    "| **Clean Up** | Stop services, clean data |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- **RAG Blueprint**: [NVIDIA RAG Documentation](https://docs.nvidia.com/ai-enterprise/rag-blueprints/latest/index.html)\n",
    "- **VSS**: [Video Search & Summarization Documentation](https://docs.nvidia.com/vss/latest/index.html)\n",
    "- **NIM**: [NVIDIA NIM Documentation](https://docs.nvidia.com/nim/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Clone the repository, configure API keys, and load helper functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone Repository\n",
    "\n",
    "Clone the RAG Blueprint repo (includes consumer code and sample data).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo and install dependencies\n",
    "import subprocess, sys, os\n",
    "\n",
    "RAG_REPO_DIR = os.path.expanduser(\"~/rag\")\n",
    "RAG_BRANCH = \"minh/aidp-notebook\"\n",
    "\n",
    "if os.path.exists(os.path.join(RAG_REPO_DIR, \"examples/rag_event_ingest\")):\n",
    "    print(f\"[OK] RAG repo already cloned: {RAG_REPO_DIR}\")\n",
    "else:\n",
    "    print(f\"Cloning branch {RAG_BRANCH}...\")\n",
    "    subprocess.run(\n",
    "        f\"git clone -b {RAG_BRANCH} https://github.com/NVIDIA-AI-Blueprints/rag.git {RAG_REPO_DIR}\",\n",
    "        shell=True,\n",
    "    )\n",
    "    subprocess.run(\"git lfs pull\", shell=True, cwd=RAG_REPO_DIR)\n",
    "    print(f\"[OK] Cloned to {RAG_REPO_DIR}\")\n",
    "\n",
    "# Verify structure\n",
    "for path in [\"deploy/compose\", \"examples/rag_event_ingest/kafka_consumer\", \"examples/rag_event_ingest/data\"]:\n",
    "    status = \"[OK]\" if os.path.exists(os.path.join(RAG_REPO_DIR, path)) else \"[MISSING]\"\n",
    "    print(f\"  {status} {path}\")\n",
    "\n",
    "# Install dependencies\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"minio\", \"aiohttp\", \"requests\", \"python-dotenv\"])\n",
    "print(\"[OK] Dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set API Keys\n",
    "\n",
    "Configure NGC and HuggingFace API keys for NIM deployments and model downloads.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "def set_api_key(env_var: str, prompt: str, required: bool = True):\n",
    "    if os.environ.get(env_var):\n",
    "        print(f\"  [OK] {env_var} already set ({os.environ[env_var][:10]}...)\")\n",
    "        return True\n",
    "    key = getpass.getpass(prompt)\n",
    "    if key:\n",
    "        os.environ[env_var] = key\n",
    "        print(f\"  [OK] {env_var} set\")\n",
    "        return True\n",
    "    if required:\n",
    "        print(f\"  [ERROR] {env_var} is required\")\n",
    "        return False\n",
    "    print(f\"  [SKIP] {env_var} (optional)\")\n",
    "    return True\n",
    "\n",
    "set_api_key(\"NGC_API_KEY\", \"Enter NGC_API_KEY (starts with 'nvapi-'): \", required=True)\n",
    "set_api_key(\"HF_TOKEN\", \"Enter HF_TOKEN (optional, press Enter to skip): \", required=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Functions\n",
    "\n",
    "Shared utilities for deployment, file upload, status checks, and RAG queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded!\n",
      "Host IP: 10.86.1.245\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json, re, subprocess, time, socket, asyncio\n",
    "import aiohttp, requests\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "try:\n",
    "    from minio import Minio\n",
    "    from minio.error import S3Error\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"minio\"])\n",
    "    from minio import Minio\n",
    "    from minio.error import S3Error\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Paths relative to RAG repo root\n",
    "RAG_REPO_DIR = os.path.expanduser(\"~/rag\")\n",
    "EXAMPLE_DIR = os.path.join(RAG_REPO_DIR, \"examples/rag_event_ingest\")\n",
    "AIDP_COMPOSE_FILE = os.path.join(EXAMPLE_DIR, \"deploy/docker-compose.yaml\")\n",
    "DATA_DIR = os.path.join(EXAMPLE_DIR, \"data\")\n",
    "RAG_SERVER_URL = \"http://localhost:8081\"\n",
    "INGESTOR_URL = \"http://localhost:8082\"\n",
    "\n",
    "VSS_DIR = os.path.expanduser(\"~/video-search-and-summarization\")\n",
    "VSS_UI_PORT = 9110\n",
    "VSS_API_PORT = 8110\n",
    "VSS_LLM_PORT = 8107\n",
    "VSS_EMBED_PORT = 8106\n",
    "VSS_RERANK_PORT = 8105\n",
    "LOCAL_NIM_CACHE = os.path.expanduser(\"~/.cache/nim\")\n",
    "\n",
    "MINIO_ENDPOINT = \"localhost:9201\"\n",
    "MINIO_ACCESS_KEY = \"minioadmin\"\n",
    "MINIO_SECRET_KEY = \"minioadmin\"\n",
    "MINIO_BUCKET = \"aidp-bucket\"\n",
    "MINIO_COLLECTION = \"aidp_bucket\"\n",
    "MINIO_CONSOLE_PORT = 9211\n",
    "\n",
    "# =============================================================================\n",
    "# SHARED UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "def run_command(cmd: str, capture: bool = False) -> Optional[str]:\n",
    "    \"\"\"Execute a shell command and print it.\"\"\"\n",
    "    print(f\"$ {cmd}\")\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=capture, text=True)\n",
    "    return result.stdout if capture else None\n",
    "\n",
    "def get_host_ip() -> str:\n",
    "    \"\"\"Get host IP address for external access URLs.\"\"\"\n",
    "    try:\n",
    "        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "        s.connect((\"8.8.8.8\", 80))\n",
    "        ip = s.getsockname()[0]\n",
    "        s.close()\n",
    "        return ip\n",
    "    except OSError:\n",
    "        return \"localhost\"\n",
    "\n",
    "def get_minio_client() -> Minio:\n",
    "    \"\"\"Create MinIO client for AIDP bucket operations.\"\"\"\n",
    "    return Minio(MINIO_ENDPOINT, access_key=MINIO_ACCESS_KEY, secret_key=MINIO_SECRET_KEY, secure=False)\n",
    "\n",
    "def upload_file(local_path: str, object_name: Optional[str] = None) -> bool:\n",
    "    \"\"\"Upload a local file to MinIO AIDP bucket.\"\"\"\n",
    "    if not os.path.exists(local_path):\n",
    "        print(f\"[ERROR] File not found: {local_path}\")\n",
    "        return False\n",
    "    obj = object_name or os.path.basename(local_path)\n",
    "    try:\n",
    "        client = get_minio_client()\n",
    "        if not client.bucket_exists(MINIO_BUCKET):\n",
    "            client.make_bucket(MINIO_BUCKET)\n",
    "        client.fput_object(MINIO_BUCKET, obj, local_path)\n",
    "        print(f\"[OK] Uploaded: {obj}\")\n",
    "        return True\n",
    "    except S3Error as e:\n",
    "        print(f\"[ERROR] {e}\")\n",
    "        return False\n",
    "\n",
    "def get_consumer_logs(lines: int = 30) -> None:\n",
    "    \"\"\"Show recent Kafka consumer logs.\"\"\"\n",
    "    run_command(f\"docker logs kafka-consumer --tail {lines}\")\n",
    "\n",
    "async def _parse_sse_stream(resp) -> str:\n",
    "    \"\"\"Parse Server-Sent Events stream into concatenated answer text.\"\"\"\n",
    "    chunks, buf = [], \"\"\n",
    "    async for raw in resp.content.iter_any():\n",
    "        buf += raw.decode(\"utf-8\", errors=\"ignore\")\n",
    "        while \"\\n\" in buf:\n",
    "            line, buf = buf.split(\"\\n\", 1)\n",
    "            line = line.strip()\n",
    "            if not line.startswith(\"data: \"):\n",
    "                continue\n",
    "            data_str = line[6:]\n",
    "            if data_str == \"[DONE]\":\n",
    "                return \"\".join(chunks)\n",
    "            try:\n",
    "                delta = json.loads(data_str).get(\"choices\", [{}])[0].get(\"delta\", {})\n",
    "                if delta.get(\"content\"):\n",
    "                    chunks.append(delta[\"content\"])\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "    return \"\".join(chunks)\n",
    "\n",
    "async def query_rag(question: str, collection: str = None) -> Optional[str]:\n",
    "    \"\"\"Query RAG system and print the answer.\"\"\"\n",
    "    coll = collection or MINIO_COLLECTION\n",
    "    print(f\"Q: {question}\\nCollection: {coll}\\n\" + \"-\" * 40)\n",
    "\n",
    "    payload = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}],\n",
    "        \"use_knowledge_base\": True,\n",
    "        \"collection_name\": coll,\n",
    "    }\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.post(\n",
    "                f\"{RAG_SERVER_URL}/generate\", json=payload,\n",
    "                timeout=aiohttp.ClientTimeout(total=120),\n",
    "            ) as resp:\n",
    "                if resp.status != 200:\n",
    "                    print(f\"[ERROR] {resp.status}: {await resp.text()}\")\n",
    "                    return None\n",
    "\n",
    "                content_type = resp.headers.get(\"Content-Type\", \"\")\n",
    "                if \"text/event-stream\" in content_type:\n",
    "                    answer = await _parse_sse_stream(resp)\n",
    "                else:\n",
    "                    data = await resp.json()\n",
    "                    answer = data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"No answer\")\n",
    "\n",
    "                print(f\"Answer: {answer}\")\n",
    "                return answer\n",
    "    except aiohttp.ClientError as e:\n",
    "        print(f\"[ERROR] {e}\")\n",
    "        return None\n",
    "\n",
    "print(f\"[OK] Helpers loaded | Host IP: {get_host_ip()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy RAG\n",
    "\n",
    "Deploy the RAG stack: NIMs (LLM, Embedding, Reranker), Milvus vector database, Ingestor server, and RAG server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DEPLOYING RAG STACK\n",
      "============================================================\n",
      "USERID: 2833:2833\n",
      "\n",
      "[1/4] Logging in to nvcr.io...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Logged in\n",
      "\n",
      "[2/4] Deploying NIMs...\n",
      "$ docker compose -f deploy/compose/nims.yaml up -d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time=\"2026-02-11T10:13:48Z\" level=warning msg=\"Found orphan containers ([minio-setup]) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up.\"\n",
      " Container nemoretriever-embedding-ms Creating \n",
      " Container nemoretriever-ranking-ms Creating \n",
      " Container compose-page-elements-1 Creating \n",
      " Container compose-table-structure-1 Creating \n",
      " Container nim-llm-ms Creating \n",
      " Container compose-paddle-1 Creating \n",
      " Container compose-graphic-elements-1 Creating \n",
      " Container compose-paddle-1 Created \n",
      " Container compose-page-elements-1 Created \n",
      " Container nemoretriever-embedding-ms Created \n",
      " Container compose-table-structure-1 Created \n",
      " Container compose-graphic-elements-1 Created \n",
      " Container nemoretriever-ranking-ms Created \n",
      " Container nim-llm-ms Created \n",
      " Container compose-graphic-elements-1 Starting \n",
      " Container compose-paddle-1 Starting \n",
      " Container compose-page-elements-1 Starting \n",
      " Container nemoretriever-embedding-ms Starting \n",
      " Container nemoretriever-ranking-ms Starting \n",
      " Container nim-llm-ms Starting \n",
      " Container compose-table-structure-1 Starting \n",
      " Container nemoretriever-ranking-ms Started \n",
      " Container nim-llm-ms Started \n",
      " Container nemoretriever-embedding-ms Started \n",
      " Container compose-table-structure-1 Started \n",
      " Container compose-paddle-1 Started \n",
      " Container compose-graphic-elements-1 Started \n",
      " Container compose-page-elements-1 Started \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/4] Deploying Vector DB...\n",
      "$ docker compose -f deploy/compose/vectordb.yaml up -d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time=\"2026-02-11T10:13:49Z\" level=warning msg=\"Found orphan containers ([nim-llm-ms nemoretriever-ranking-ms compose-table-structure-1 nemoretriever-embedding-ms compose-graphic-elements-1 compose-page-elements-1 compose-paddle-1 minio-setup]) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up.\"\n",
      " Container milvus-minio Creating \n",
      " Container milvus-etcd Creating \n",
      " Container milvus-etcd Created \n",
      " Container milvus-minio Created \n",
      " Container milvus-standalone Creating \n",
      " Container milvus-standalone Created \n",
      " Container milvus-minio Starting \n",
      " Container milvus-etcd Starting \n",
      " Container milvus-etcd Started \n",
      " Container milvus-minio Started \n",
      " Container milvus-standalone Starting \n",
      " Container milvus-standalone Started \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Waiting for Milvus (30s)...\n",
      "\n",
      "[4/4] Deploying Ingestor and RAG Server...\n",
      "$ docker compose -f deploy/compose/docker-compose-ingestor-server.yaml up -d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time=\"2026-02-11T10:14:20Z\" level=warning msg=\"Found orphan containers ([milvus-standalone milvus-etcd milvus-minio nim-llm-ms nemoretriever-ranking-ms compose-table-structure-1 nemoretriever-embedding-ms compose-graphic-elements-1 compose-page-elements-1 compose-paddle-1 minio-setup]) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up.\"\n",
      " Container compose-redis-1 Creating \n",
      " Container ingestor-server Creating \n",
      " Container compose-nv-ingest-ms-runtime-1 Creating \n",
      " Container ingestor-server Created \n",
      " Container compose-redis-1 Created \n",
      " Container compose-nv-ingest-ms-runtime-1 Created \n",
      " Container ingestor-server Starting \n",
      " Container compose-redis-1 Starting \n",
      " Container compose-nv-ingest-ms-runtime-1 Starting \n",
      " Container compose-nv-ingest-ms-runtime-1 Started \n",
      " Container ingestor-server Started \n",
      " Container compose-redis-1 Started \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ docker compose -f deploy/compose/docker-compose-rag-server.yaml up -d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time=\"2026-02-11T10:14:21Z\" level=warning msg=\"Found orphan containers ([compose-redis-1 compose-nv-ingest-ms-runtime-1 ingestor-server milvus-standalone milvus-etcd milvus-minio nim-llm-ms nemoretriever-ranking-ms compose-table-structure-1 nemoretriever-embedding-ms compose-graphic-elements-1 compose-page-elements-1 compose-paddle-1 minio-setup]) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up.\"\n",
      " Container rag-server Creating \n",
      " Container rag-server Created \n",
      " Container rag-frontend Creating \n",
      " Container rag-frontend Created \n",
      " Container rag-server Starting \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RAG DEPLOYED!\n",
      "============================================================\n",
      "  RAG Server:      http://10.86.1.245:8081\n",
      "  Ingestor Server: http://10.86.1.245:8082\n",
      "  RAG Frontend:    http://10.86.1.245:8090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container rag-server Started \n",
      " Container rag-frontend Starting \n",
      " Container rag-frontend Started \n"
     ]
    }
   ],
   "source": [
    "ngc_key = os.environ.get(\"NGC_API_KEY\")\n",
    "if not ngc_key:\n",
    "    raise RuntimeError(\"NGC_API_KEY not set! Run the API keys cell first.\")\n",
    "\n",
    "os.chdir(RAG_REPO_DIR)\n",
    "os.environ[\"USERID\"] = f\"{os.getuid()}:{os.getgid()}\"\n",
    "\n",
    "# Login to nvcr.io\n",
    "subprocess.run(f\"docker login nvcr.io -u '$oauthtoken' -p {ngc_key}\",\n",
    "               shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Deploy components sequentially\n",
    "for label, compose_file in [\n",
    "    (\"NIMs\",      \"deploy/compose/nims.yaml\"),\n",
    "    (\"Vector DB\", \"deploy/compose/vectordb.yaml\"),\n",
    "]:\n",
    "    print(f\"Deploying {label}...\")\n",
    "    run_command(f\"docker compose -f {compose_file} up -d\")\n",
    "\n",
    "print(\"Waiting 30s for Milvus...\")\n",
    "time.sleep(30)\n",
    "\n",
    "for label, compose_file in [\n",
    "    (\"Ingestor\", \"deploy/compose/docker-compose-ingestor-server.yaml\"),\n",
    "    (\"RAG Server\", \"deploy/compose/docker-compose-rag-server.yaml\"),\n",
    "]:\n",
    "    print(f\"Deploying {label}...\")\n",
    "    run_command(f\"docker compose -f {compose_file} up -d\")\n",
    "\n",
    "ip = get_host_ip()\n",
    "print(f\"\\nRAG deployed: http://{ip}:8081 (server) | http://{ip}:8082 (ingestor) | http://{ip}:8090 (UI)\")\n",
    "print(\"Wait 2-5 minutes for NIMs to load models, then run the status check cell.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Verify RAG services are healthy. Wait 2-5 minutes for NIMs to load models.\n"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait 2-5 minutes for services to become healthy.\n",
      "Run this cell again after waiting.\n",
      "\n",
      "RAG Services Status:\n",
      "============================================================\n",
      "  [OK] RAG Server: http://10.86.1.245:8081\n",
      "  [OK] Ingestor Server: http://10.86.1.245:8082\n",
      "  [OK] RAG Frontend: http://10.86.1.245:8090\n",
      "  [OK] Milvus: http://10.86.1.245:19530\n",
      "\n",
      "Container Status:\n",
      "$ docker ps --format 'table {{.Names}}\t{{.Status}}' | grep -E '(rag|milvus|ingestor|nim-llm|NAMES)'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMES                                             STATUS\n",
      "rag-frontend                                      Up 50 seconds\n",
      "rag-server                                        Up 51 seconds\n",
      "ingestor-server                                   Up 51 seconds\n",
      "milvus-standalone                                 Up About a minute\n",
      "milvus-etcd                                       Up About a minute (healthy)\n",
      "milvus-minio                                      Up About a minute (healthy)\n",
      "nim-llm-ms                                        Up About a minute (healthy)\n",
      "local_deployment_single_gpu-milvus-standalone-1   Up 5 minutes (healthy)\n"
     ]
    }
   ],
   "source": [
    "print(\"Wait 2-5 minutes for services to become healthy.\")\n",
    "print(\"Run this cell again after waiting.\\n\")\n",
    "\n",
    "ip = get_host_ip()\n",
    "for name, port, path in [\n",
    "    (\"RAG Server\", 8081, \"/health\"), (\"Ingestor\", 8082, \"/health\"),\n",
    "    (\"Frontend\", 8090, \"/\"), (\"Milvus\", 19530, \"/v1/vector/collections\"),\n",
    "]:\n",
    "    try:\n",
    "        s = \"[OK]\" if requests.get(f\"http://localhost:{port}{path}\", timeout=10).status_code == 200 else \"[WARN]\"\n",
    "    except requests.ConnectionError:\n",
    "        s = \"[DOWN]\"\n",
    "    except requests.Timeout:\n",
    "        s = \"[TIMEOUT]\"\n",
    "    print(f\"  {s} {name}: http://{ip}:{port}\")\n",
    "run_command(\"docker ps --format 'table {{.Names}}\\t{{.Status}}' | grep -E '(rag|milvus|ingestor|nim|NAMES)'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy VSS\n",
    "\n",
    "Deploy the VSS stack: NIMs (LLM, Embedding, Reranker) and VLM for video analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DEPLOYING VSS STACK\n",
      "============================================================\n",
      "NIM GPU: 4  |  VLM GPU: 5\n",
      "\n",
      "[0/5] Logging in to nvcr.io...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [OK] Logged in to nvcr.io\n",
      "\n",
      "[1/5] Cloning VSS repository...\n",
      "  [OK] VSS repo exists: /localhome/local-minhngu/video-search-and-summarization\n",
      "\n",
      "[2/5] Deploying LLM NIM...\n",
      "\n",
      "[VSS-LLM] Deploying Llama 3.1 8B on GPU 4...\n",
      "  [OK] LLM NIM started on port 8107\n",
      "\n",
      "[3/5] Deploying Embedding NIM...\n",
      "\n",
      "[VSS-Embed] Deploying Embedding NIM on GPU 4...\n",
      "  [OK] Embedding NIM started on port 8106\n",
      "\n",
      "[4/5] Deploying Reranker NIM...\n",
      "\n",
      "[VSS-Rerank] Deploying Reranker NIM on GPU 4...\n",
      "  [OK] Reranker NIM started on port 8105\n",
      "\n",
      "[5/5] Deploying VSS Application (VLM on GPU 5)...\n",
      "\n",
      "[VSS-App] Deploying VSS application...\n",
      "  [OK] Created .env file\n",
      "  [OK] Patched config.yaml\n",
      "  $ docker compose up -d\n",
      "  [ERROR] VSS app failed:  Network local_deployment_single_gpu_default Creating \n",
      " Network local_deployment_single_gpu_default Created \n",
      " Container local_deployment_single_gpu-milvus-standalone-1 Creating \n",
      " Container local_deployment_single_gpu-graph-db-1 Creating \n",
      " Container local_deployment_single_gpu-elasticsearch-1 Creatin\n",
      "\n",
      "============================================================\n",
      "VSS DEPLOYED!\n",
      "============================================================\n",
      "\n",
      "Access:\n",
      "  VSS UI:      http://10.86.1.245:9110\n",
      "  VSS API:     http://10.86.1.245:8110\n",
      "  LLM NIM:     http://10.86.1.245:8107\n",
      "  Embedding:   http://10.86.1.245:8106\n",
      "  Reranker:    http://10.86.1.245:8105\n",
      "\n",
      "Wait 2-5 minutes for NIMs to load models.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VSS deployment configuration\n",
    "VSS_REPO_URL = \"https://github.com/NVIDIA-AI-Blueprints/video-search-and-summarization.git\"\n",
    "VSS_GPU_DEVICE = 4       # GPU for NIMs (LLM, Embedding, Reranker)\n",
    "VSS_VLM_GPU_DEVICE = 5   # GPU for VLM (via-server with Cosmos-Reason2)\n",
    "\n",
    "NIM_IMAGES = {\n",
    "    \"vss-llm\":       (\"nvcr.io/nim/meta/llama-3.1-8b-instruct:1.12.0\",      VSS_LLM_PORT),\n",
    "    \"vss-embedding\": (\"nvcr.io/nim/nvidia/llama-3.2-nv-embedqa-1b-v2:1.9.0\", VSS_EMBED_PORT),\n",
    "    \"vss-reranker\":  (\"nvcr.io/nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:1.7.0\", VSS_RERANK_PORT),\n",
    "}\n",
    "\n",
    "ngc_key = os.environ.get(\"NGC_API_KEY\", \"\")\n",
    "hf_token = os.environ.get(\"HF_TOKEN\", \"\")\n",
    "if not ngc_key:\n",
    "    raise RuntimeError(\"NGC_API_KEY not set!\")\n",
    "\n",
    "# Docker login\n",
    "subprocess.run(f\"echo {ngc_key} | docker login nvcr.io -u '$oauthtoken' --password-stdin\",\n",
    "               shell=True, capture_output=True, text=True, executable=\"/bin/bash\")\n",
    "\n",
    "# Clone VSS repo\n",
    "if not os.path.exists(VSS_DIR):\n",
    "    print(f\"Cloning {VSS_REPO_URL}...\")\n",
    "    subprocess.run(f\"git clone {VSS_REPO_URL} {VSS_DIR}\", shell=True)\n",
    "else:\n",
    "    print(f\"[OK] VSS repo exists: {VSS_DIR}\")\n",
    "\n",
    "# Deploy NIM containers (all on same GPU)\n",
    "os.makedirs(LOCAL_NIM_CACHE, exist_ok=True)\n",
    "for name, (image, port) in NIM_IMAGES.items():\n",
    "    subprocess.run(f\"docker rm -f {name} 2>/dev/null\", shell=True, capture_output=True)\n",
    "    cmd = f\"\"\"docker run -d --name {name} \\\n",
    "        -u $(id -u) --gpus '\"device={VSS_GPU_DEVICE}\"' --shm-size=16GB \\\n",
    "        --network nvidia-rag -e NGC_API_KEY={ngc_key} \\\n",
    "        -v \"{LOCAL_NIM_CACHE}:/opt/nim/.cache\" \\\n",
    "        -p {port}:8000 -e NIM_LOW_MEMORY_MODE=1 -e NIM_RELAX_MEM_CONSTRAINTS=1 \\\n",
    "        {image}\"\"\"\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True, executable=\"/bin/bash\")\n",
    "    status = \"[OK]\" if result.returncode == 0 else \"[ERROR]\"\n",
    "    print(f\"  {status} {name} -> port {port}\")\n",
    "\n",
    "# Deploy VSS application (VLM on separate GPU)\n",
    "vss_deploy_dir = f\"{VSS_DIR}/deploy/docker/local_deployment_single_gpu\"\n",
    "env_content = f\"\"\"NGC_API_KEY={ngc_key}\n",
    "HF_TOKEN={hf_token}\n",
    "VIA_IMAGE=nvcr.io/nvidia/blueprint/vss-engine:2.4.1\n",
    "FRONTEND_PORT={VSS_UI_PORT}\n",
    "BACKEND_PORT={VSS_API_PORT}\n",
    "MILVUS_DB_HTTP_PORT=19091\n",
    "MILVUS_DB_GRPC_PORT=29530\n",
    "MINIO_PORT=9002\n",
    "MINIO_WEBUI_PORT=9003\n",
    "GRAPH_DB_USERNAME=neo4j\n",
    "GRAPH_DB_PASSWORD=password\n",
    "ARANGO_DB_USERNAME=arangodb\n",
    "ARANGO_DB_PASSWORD=password\n",
    "CA_RAG_CONFIG=./config.yaml\n",
    "GUARDRAILS_CONFIG=./guardrails\n",
    "NVIDIA_VISIBLE_DEVICES={VSS_VLM_GPU_DEVICE}\n",
    "VLM_MODEL_TO_USE=cosmos-reason2\n",
    "MODEL_PATH=git:https://huggingface.co/nvidia/Cosmos-Reason2-8B\n",
    "VLLM_GPU_MEMORY_UTILIZATION=0.4\n",
    "VLM_MAX_MODEL_LEN=20480\n",
    "DISABLE_GUARDRAILS=true\n",
    "DISABLE_CV_PIPELINE=true\n",
    "ENABLE_AUDIO=false\n",
    "\"\"\"\n",
    "with open(f\"{vss_deploy_dir}/.env\", \"w\") as f:\n",
    "    f.write(env_content)\n",
    "\n",
    "# Patch config.yaml to use our NIM ports\n",
    "config_file = f\"{vss_deploy_dir}/config.yaml\"\n",
    "if os.path.exists(config_file):\n",
    "    cfg = open(config_file).read()\n",
    "    cfg = re.sub(r\":8007/v1\", f\":{VSS_LLM_PORT}/v1\", cfg)\n",
    "    cfg = re.sub(r\":8006/v1\", f\":{VSS_EMBED_PORT}/v1\", cfg)\n",
    "    cfg = re.sub(r\":8005/v1\", f\":{VSS_RERANK_PORT}/v1\", cfg)\n",
    "    open(config_file, \"w\").write(cfg)\n",
    "\n",
    "cmd = f\"cd {vss_deploy_dir} && set -a && source .env && set +a && docker compose up -d\"\n",
    "subprocess.run(cmd, shell=True, capture_output=True, text=True, executable=\"/bin/bash\")\n",
    "\n",
    "ip = get_host_ip()\n",
    "print(f\"\\nVSS deployed: http://{ip}:{VSS_UI_PORT} (UI) | http://{ip}:{VSS_API_PORT} (API)\")\n",
    "print(\"Wait 2-5 minutes for NIMs to load models, then run the status check cell.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Verify VSS services are healthy. Wait 2-5 minutes for NIMs to load models.\n"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VSS Services Status:\n",
      "============================================================\n",
      "  [OK] VSS UI: http://10.86.1.245:9110\n",
      "  [OK] VSS API: http://10.86.1.245:8110\n",
      "  [OK] VSS LLM NIM: http://10.86.1.245:8107\n",
      "  [OK] VSS Embedding: http://10.86.1.245:8106\n",
      "  [OK] VSS Reranker: http://10.86.1.245:8105\n",
      "\n",
      "Container Status:\n",
      "$ docker ps --format 'table {{.Names}}\t{{.Status}}' | grep -E '(vss|via|local_deployment|NAMES)'\n",
      "NAMES                                             STATUS\n",
      "local_deployment_single_gpu-via-server-1          Up 2 minutes\n",
      "local_deployment_single_gpu-elasticsearch-1       Up 3 minutes\n",
      "local_deployment_single_gpu-graph-db-1            Up 3 minutes\n",
      "local_deployment_single_gpu-minio-1               Up 2 minutes\n",
      "local_deployment_single_gpu-arango-db-1           Up 3 minutes\n",
      "local_deployment_single_gpu-milvus-standalone-1   Up 3 minutes (healthy)\n",
      "vss-reranker                                      Up 3 minutes\n",
      "vss-embedding                                     Up 3 minutes\n",
      "vss-llm                                           Up 3 minutes\n"
     ]
    }
   ],
   "source": [
    "ip = get_host_ip()\n",
    "for name, port, path in [\n",
    "    (\"VSS UI\", VSS_UI_PORT, \"/\"), (\"VSS API\", VSS_API_PORT, \"/\"),\n",
    "    (\"LLM NIM\", VSS_LLM_PORT, \"/v1/health/ready\"),\n",
    "    (\"Embedding\", VSS_EMBED_PORT, \"/v1/health/ready\"),\n",
    "    (\"Reranker\", VSS_RERANK_PORT, \"/v1/health/ready\"),\n",
    "]:\n",
    "    try:\n",
    "        requests.get(f\"http://localhost:{port}{path}\", timeout=10)\n",
    "        s = \"[OK]\"\n",
    "    except requests.ConnectionError:\n",
    "        s = \"[DOWN]\"\n",
    "    except requests.Timeout:\n",
    "        s = \"[TIMEOUT]\"\n",
    "    print(f\"  {s} {name}: http://{ip}:{port}\")\n",
    "run_command(\"docker ps --format 'table {{.Names}}\\t{{.Status}}' | grep -E '(vss|via|local_deployment|NAMES)'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy AIDP\n",
    "\n",
    "Deploy the AIDP stack: Kafka message broker, MinIO object storage, and Kafka consumer for automated ingestion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DEPLOYING AIDP STACK\n",
      "============================================================\n",
      "Using host IP: 10.86.1.245\n",
      "\n",
      "[1/4] Checking prerequisites...\n",
      "[OK] nvidia-rag network exists\n",
      "[OK] RAG services detected\n",
      "\n",
      "[2/4] Logging in to nvcr.io...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Logged in to nvcr.io\n",
      "\n",
      "[3/4] Pulling images...\n",
      "Running: pull...\n",
      "[OK] pull complete\n",
      "\n",
      "[4/4] Starting services...\n",
      "Running: up...\n",
      "[OK] up complete\n",
      "\n",
      "============================================================\n",
      "AIDP DEPLOYED!\n",
      "============================================================\n",
      "\n",
      "Services:\n",
      "  Kafka UI:       http://localhost:8080\n",
      "  MinIO Console:  http://localhost:9211\n",
      "  MinIO API:      http://localhost:9201\n",
      "\n",
      "Credentials: minioadmin / minioadmin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify prerequisites\n",
    "net_check = subprocess.run(\"docker network inspect nvidia-rag\", shell=True, capture_output=True)\n",
    "if net_check.returncode != 0:\n",
    "    raise RuntimeError(\"nvidia-rag network not found. Deploy RAG first.\")\n",
    "\n",
    "ngc_key = os.environ.get(\"NGC_API_KEY\", \"\")\n",
    "if not ngc_key:\n",
    "    raise RuntimeError(\"NGC_API_KEY not set!\")\n",
    "\n",
    "host_ip = get_host_ip()\n",
    "os.environ[\"VSS_SERVER_URL\"] = f\"http://{host_ip}:{VSS_API_PORT}\"\n",
    "\n",
    "# Login + pull + build\n",
    "subprocess.run(f\"echo {ngc_key} | docker login nvcr.io -u '$oauthtoken' --password-stdin\",\n",
    "               shell=True, capture_output=True, text=True, executable=\"/bin/bash\")\n",
    "\n",
    "compose = f\"docker compose -f {AIDP_COMPOSE_FILE}\"\n",
    "subprocess.run(f\"{compose} pull --ignore-pull-failures\", shell=True, capture_output=True, text=True, executable=\"/bin/bash\")\n",
    "subprocess.run(f\"{compose} up -d --build\", shell=True, capture_output=True, text=True, executable=\"/bin/bash\")\n",
    "\n",
    "print(f\"AIDP deployed:\")\n",
    "print(f\"  Kafka UI:      http://{host_ip}:8080\")\n",
    "print(f\"  MinIO Console: http://{host_ip}:{MINIO_CONSOLE_PORT}\")\n",
    "print(f\"  Credentials:   minioadmin / minioadmin\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Verify AIDP services are running.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIDP Services Status:\n",
      "============================================================\n",
      "  Kafka UI: http://10.86.1.245:8080\n",
      "  MinIO Console: http://10.86.1.245:9211\n",
      "  MinIO API: http://10.86.1.245:9201\n",
      "\n",
      "Credentials: minioadmin / minioadmin\n",
      "\n",
      "Container Status:\n",
      "$ docker ps --format 'table {{.Names}}\t{{.Status}}' | grep -E '(kafka|minio|NAMES)'\n",
      "NAMES                                             STATUS\n",
      "kafka-consumer                                    Up 4 seconds\n",
      "aidp-minio-mc                                     Up 4 seconds\n",
      "aidp-kafka-ui                                     Up 4 seconds\n",
      "kafka                                             Up 36 seconds (healthy)\n",
      "aidp-minio                                        Up 36 seconds (healthy)\n",
      "milvus-minio                                      Up 2 minutes (healthy)\n",
      "local_deployment_single_gpu-minio-1               Up 4 minutes\n",
      "\n",
      "RAG Services Status:\n",
      "============================================================\n",
      "  [OK] RAG Server: http://10.86.1.245:8081\n",
      "  [OK] Ingestor Server: http://10.86.1.245:8082\n",
      "  [OK] RAG Frontend: http://10.86.1.245:8090\n",
      "  [OK] Milvus: http://10.86.1.245:19530\n",
      "\n",
      "Container Status:\n",
      "$ docker ps --format 'table {{.Names}}\t{{.Status}}' | grep -E '(rag|milvus|ingestor|nim-llm|NAMES)'\n",
      "NAMES                                             STATUS\n",
      "rag-frontend                                      Up About a minute\n",
      "rag-server                                        Up About a minute\n",
      "ingestor-server                                   Up 2 minutes\n",
      "milvus-standalone                                 Up 2 minutes\n",
      "milvus-etcd                                       Up 2 minutes (healthy)\n",
      "milvus-minio                                      Up 2 minutes (healthy)\n",
      "nim-llm-ms                                        Up 2 minutes (healthy)\n",
      "local_deployment_single_gpu-milvus-standalone-1   Up 6 minutes (healthy)\n"
     ]
    }
   ],
   "source": [
    "ip = get_host_ip()\n",
    "print(f\"  Kafka UI:      http://{ip}:8080\")\n",
    "print(f\"  MinIO Console: http://{ip}:{MINIO_CONSOLE_PORT}\")\n",
    "run_command(\"docker ps --format 'table {{.Names}}\\t{{.Status}}' | grep -E '(kafka|minio|NAMES)'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Wait for all services (RAG, VSS, AIDP) to stabilize before testing.\n"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for services to be ready...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service Health Check:\n",
      "========================================\n",
      "RAG Server:      [OK] (200)\n",
      "Ingestor Server: [OK] (200)\n",
      "MinIO:           [OK]\n"
     ]
    }
   ],
   "source": [
    "# Wait for services to be ready\n",
    "print(\"Waiting for services to be ready...\")\n",
    "time.sleep(15)\n",
    "\n",
    "# Check health\n",
    "await check_health()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Test the deployment by uploading documents and videos, then querying via RAG.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document Upload\n",
    "\n",
    "Upload a PDF document to MinIO, which triggers automatic ingestion via Kafka consumer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Upload to Storage\n",
    "\n",
    "Upload the document to MinIO object storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Uploaded: Seahawks-Patriots_SuperBowl_LX_Analysis.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample documents are included in the repo under examples/rag_event_ingest/data/\n",
    "pdf_path = os.path.join(DATA_DIR, \"documents\", \"Seahawks-Patriots in Super Bowl LX_ What We Learned from Seattle's 29-13 win.pdf\")\n",
    "upload_file(pdf_path, \"Seahawks-Patriots_SuperBowl_LX_Analysis.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Check consumer logs to verify the document was processed.\n"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for processing...\n",
      "Consumer Logs (last 50 lines):\n",
      "============================================================\n",
      "$ docker logs kafka-consumer --tail 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        \"x-minio-origin-endpoint\": \"http://172.18.0.21:9000\"\n",
      "      },\n",
      "      \"s3\": {\n",
      "        \"s3SchemaVersion\": \"1.0\",\n",
      "        \"configurationId\": \"Config\",\n",
      "        \"bucket\": {\n",
      "          \"name\": \"aidp-bucket\",\n",
      "          \"ownerIdentity\": {\n",
      "            \"principalId\": \"minioadmin\"\n",
      "          },\n",
      "          \"arn\": \"arn:aws:s3:::aidp-bucket\"\n",
      "        },\n",
      "        \"object\": {\n",
      "          \"key\": \"Seahawks-Patriots_SuperBowl_LX_Analysis.pdf\",\n",
      "          \"size\": 6084589,\n",
      "          \"eTag\": \"b62aa96fc8551ff52f2a0b06495f751a-2\",\n",
      "          \"contentType\": \"application/octet-stream\",\n",
      "          \"userMetadata\": {\n",
      "            \"content-type\": \"application/octet-stream\"\n",
      "          },\n",
      "          \"sequencer\": \"189329C5DBD3009B\"\n",
      "        }\n",
      "      },\n",
      "      \"source\": {\n",
      "        \"host\": \"172.18.0.1\",\n",
      "        \"port\": \"\",\n",
      "        \"userAgent\": \"MinIO (Linux; x86_64) minio-py/7.2.0\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "2026-02-11 10:16:48,272 - consumer - INFO - Processing: aidp-bucket/Seahawks-Patriots_SuperBowl_LX_Analysis.pdf (6084589 bytes)\n",
      "2026-02-11 10:16:48,272 - consumer - INFO - \ud83d\udcc1 document \u2192 rag\n",
      "2026-02-11 10:16:48,272 - handlers.base - INFO - [DocumentHandler] Processing aidp-bucket/Seahawks-Patriots_SuperBowl_LX_Analysis.pdf\n",
      "2026-02-11 10:16:48,272 - handlers.document - INFO - \ud83d\udd04 Checking for existing entries of Seahawks-Patriots_SuperBowl_LX_Analysis.pdf...\n",
      "2026-02-11 10:16:48,272 - services.document_indexer - INFO - Deleting 'Seahawks-Patriots_SuperBowl_LX_Analysis.pdf' from 'aidp_bucket'\n",
      "2026-02-11 10:16:48,511 - services.document_indexer - INFO - Deleted 'Seahawks-Patriots_SuperBowl_LX_Analysis.pdf'\n",
      "2026-02-11 10:16:48,511 - handlers.document - INFO - \ud83d\udce5 Downloading from storage...\n",
      "2026-02-11 10:16:48,518 - services.storage - INFO - Downloaded aidp-bucket/Seahawks-Patriots_SuperBowl_LX_Analysis.pdf (6084589 bytes)\n",
      "2026-02-11 10:16:48,518 - handlers.document - INFO - \ud83d\udce4 Sending to indexer...\n",
      "2026-02-11 10:16:48,732 - services.document_indexer - INFO - Creating collection 'aidp_bucket'...\n",
      "2026-02-11 10:16:48,963 - services.document_indexer - INFO - \u2713 Collection 'aidp_bucket' created\n",
      "2026-02-11 10:16:48,963 - services.document_indexer - INFO - Uploading to collection: aidp_bucket\n",
      "2026-02-11 10:16:49,335 - services.document_indexer - INFO - \u2713 File uploaded, task_id: 0c7825b4-ba08-4911-bf4a-0c79493a5a00\n",
      "2026-02-11 10:16:49,336 - handlers.document - INFO - \u23f3 Waiting for indexing (task_id: 0c7825b4-ba08-4911-bf4a-0c79493a5a00)...\n",
      "2026-02-11 10:16:49,349 - services.document_indexer - INFO - Task 0c7825b4-ba08-4911-bf4a-0c79493a5a00: PENDING (0s)\n",
      "2026-02-11 10:16:54,363 - services.document_indexer - INFO - Task 0c7825b4-ba08-4911-bf4a-0c79493a5a00: PENDING (5s)\n",
      "2026-02-11 10:16:59,377 - services.document_indexer - INFO - Task 0c7825b4-ba08-4911-bf4a-0c79493a5a00: PENDING (10s)\n",
      "2026-02-11 10:17:02,386 - handlers.base - INFO - [DocumentHandler] \u2713 Seahawks-Patriots_SuperBowl_LX_Analysis.pdf \u2192 SUCCESS\n",
      "2026-02-11 10:17:02,387 - consumer - INFO - \u2713 SUMMARY: Seahawks-Patriots_SuperBowl_LX_Analysis.pdf | Collection: aidp_bucket | Duration: 14.11s | Status: SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# Check consumer logs to see processing\n",
    "print(\"Waiting for processing...\")\n",
    "get_consumer_logs(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Verify Document Ingestion\n",
    "\n",
    "Verify the document was ingested into the RAG system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collections:\n",
      "  - {'collection_name': 'metadata_schema', 'num_entities': 1, 'metadata_schema': []}\n",
      "  - {'collection_name': 'aidp_bucket', 'num_entities': 14, 'metadata_schema': [{'name': 'filename', 'type': 'string', 'required': False, 'array_type': None, 'max_length': None, 'description': 'Name of the uploaded file'}]}\n",
      "  - {'collection_name': 'meta', 'num_entities': 34, 'metadata_schema': []}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'collection_name': 'metadata_schema',\n",
       "  'num_entities': 1,\n",
       "  'metadata_schema': []},\n",
       " {'collection_name': 'aidp_bucket',\n",
       "  'num_entities': 14,\n",
       "  'metadata_schema': [{'name': 'filename',\n",
       "    'type': 'string',\n",
       "    'required': False,\n",
       "    'array_type': None,\n",
       "    'max_length': None,\n",
       "    'description': 'Name of the uploaded file'}]},\n",
       " {'collection_name': 'meta', 'num_entities': 34, 'metadata_schema': []}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = requests.get(f\"{INGESTOR_URL}/v1/collections\", timeout=10)\n",
    "collections = resp.json().get(\"collections\", []) if resp.status_code == 200 else []\n",
    "print(\"Collections:\", collections)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "List documents ingested into the collection.\n"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents in 'aidp_bucket' (3):\n",
      "  - Seahawks-Patriots in Super Bowl LX_ What We Learned from Seattle's 29-13 win.pdf\n",
      "  - Seattle Seahawks vs New England Patriots - Super Bowl LX Game Highlights.mp4_description.json\n",
      "  - Seahawks-Patriots_SuperBowl_LX_Analysis.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'document_name': \"Seahawks-Patriots in Super Bowl LX_ What We Learned from Seattle's 29-13 win.pdf\",\n",
       "  'metadata': {'filename': \"Seahawks-Patriots in Super Bowl LX_ What We Learned from Seattle's 29-13 win.pdf\"}},\n",
       " {'document_name': 'Seattle Seahawks vs New England Patriots - Super Bowl LX Game Highlights.mp4_description.json',\n",
       "  'metadata': {'filename': 'Seattle Seahawks vs New England Patriots - Super Bowl LX Game Highlights.mp4_description.json'}},\n",
       " {'document_name': 'Seahawks-Patriots_SuperBowl_LX_Analysis.pdf',\n",
       "  'metadata': {'filename': 'Seahawks-Patriots_SuperBowl_LX_Analysis.pdf'}}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = requests.get(f\"{INGESTOR_URL}/documents\", params={\"collection_name\": MINIO_COLLECTION}, timeout=10)\n",
    "docs = resp.json().get(\"documents\", []) if resp.status_code == 200 else []\n",
    "print(f\"Documents in '{MINIO_COLLECTION}' ({len(docs)}):\")\n",
    "for d in docs:\n",
    "    print(f\"  - {d.get('document_name', '?')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check consumer logs to verify document processing status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check document processing status\n",
    "print(\"Waiting for document processing...\")\n",
    "get_consumer_logs(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Query Document via RAG\n",
    "\n",
    "Query the ingested document using natural language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What was the final score and who won Super Bowl LX?\n",
      "Collection: aidp_bucket\n",
      "----------------------------------------\n",
      "Answer: The final score was Seattle 29, New England 13. The Seattle Seahawks won Super Bowl LX.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The final score was Seattle 29, New England 13. The Seattle Seahawks won Super Bowl LX.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the document\n",
    "await query_rag(\"What was the final score and who won Super Bowl LX?\", MINIO_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Ask another question about the document.\n"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What were the key lessons learned from Seattle's victory in Super Bowl LX?\n",
      "Collection: aidp_bucket\n",
      "----------------------------------------\n",
      "Answer: Seattle's defense dominated the game, playing to their No. 1 ranking and sacking Drake Maye six times while generating two interceptions. The Seahawks excelled in all three phases of the game, with special teams making a significant impact through consistent field position advantages. Kenneth Walker III demonstrated strong rushing performance, gaining significant yards over expected. The team's ability to capitalize on stalled drives with points and their defensive depth were crucial in securing the victory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Seattle's defense dominated the game, playing to their No. 1 ranking and sacking Drake Maye six times while generating two interceptions. The Seahawks excelled in all three phases of the game, with special teams making a significant impact through consistent field position advantages. Kenneth Walker III demonstrated strong rushing performance, gaining significant yards over expected. The team's ability to capitalize on stalled drives with points and their defensive depth were crucial in securing the victory.\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query about key takeaways\n",
    "await query_rag(\"What were the key lessons learned from Seattle's victory in Super Bowl LX?\", MINIO_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Video Upload\n",
    "\n",
    "Upload a video to MinIO, which triggers automatic ingestion via Kafka consumer \u2192 VSS for video analysis \u2192 RAG for indexing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Upload to Storage\n",
    "\n",
    "Upload the video to MinIO object storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Uploaded: Seattle Seahawks vs New England Patriots - Super Bowl LX Game Highlights.mp4\n",
      "\n",
      "Video processing takes longer than documents.\n",
      "Check consumer logs for progress:\n"
     ]
    }
   ],
   "source": [
    "# Sample videos are included in the repo under examples/rag_event_ingest/data/\n",
    "video_path = os.path.join(DATA_DIR, \"videos\", \"Seattle Seahawks vs New England Patriots - Super Bowl LX Game Highlights.mp4\")\n",
    "upload_file(video_path)\n",
    "\n",
    "print(\"\\nVideo processing takes longer than documents. Check consumer logs for progress.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Verify Video Ingestion\n",
    "\n",
    "Check consumer logs to verify video processing status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check video processing status\n",
    "print(\"Waiting for video processing...\")\n",
    "get_consumer_logs(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Query Video via RAG\n",
    "\n",
    "Query the video content using natural language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Summarize the video content\n",
      "Collection: aidp_bucket\n",
      "----------------------------------------\n",
      "Answer: The video content summarizes the Super Bowl LX game between the Seattle Seahawks and the New England Patriots. The Seahawks dominated the game, showcasing a strong defense that intercepted multiple passes and forced crucial turnovers. The Patriots struggled offensively, with quarterback Drake Maye facing pressure and struggling to find open targets. The Seahawks' offense, led by Kenneth Walker III, drove downfield multiple times, culminating in several touchdowns. The final score was 66-31 in favor of the Seattle Seahawks. Key plays included a deep pass touchdown by Russell Wilson, interceptions by the Seahawks' defense, and consistent rushing yards by Walker. The game highlighted the Seahawks' defensive dominance and the Patriots' offensive struggles.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The video content summarizes the Super Bowl LX game between the Seattle Seahawks and the New England Patriots. The Seahawks dominated the game, showcasing a strong defense that intercepted multiple passes and forced crucial turnovers. The Patriots struggled offensively, with quarterback Drake Maye facing pressure and struggling to find open targets. The Seahawks' offense, led by Kenneth Walker III, drove downfield multiple times, culminating in several touchdowns. The final score was 66-31 in favor of the Seattle Seahawks. Key plays included a deep pass touchdown by Russell Wilson, interceptions by the Seahawks' defense, and consistent rushing yards by Walker. The game highlighted the Seahawks' defensive dominance and the Patriots' offensive struggles.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query about the video content\n",
    "await query_rag(\"Summarize the video content\", MINIO_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Query about a specific time range in the video.\n"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What happened between 15:00 and 20:00?\n",
      "Collection: aidp_bucket\n",
      "----------------------------------------\n",
      "Answer: Between 15:00 and 20:00, the Seahawks' defense continued to showcase exceptional play, intercepting multiple passes and forcing crucial turnovers. In contrast, the Patriots' offense lacked consistency, struggling to move the ball effectively and converting few first downs. The turning point came when the Patriots finally found the end zone, breaking the shutout and tying the game at 3-3. Despite the late-game heroics, the overall performance highlighted the dominance of the Seahawks' defense and the offensive struggles of the Patriots. The Seahawks' defense continued to shine, intercepting a pass and returning it for a touchdown, putting them ahead 10-3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Between 15:00 and 20:00, the Seahawks' defense continued to showcase exceptional play, intercepting multiple passes and forcing crucial turnovers. In contrast, the Patriots' offense lacked consistency, struggling to move the ball effectively and converting few first downs. The turning point came when the Patriots finally found the end zone, breaking the shutout and tying the game at 3-3. Despite the late-game heroics, the overall performance highlighted the dominance of the Seahawks' defense and the offensive struggles of the Patriots. The Seahawks' defense continued to shine, intercepting a pass and returning it for a touchdown, putting them ahead 10-3.\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query about specific time range\n",
    "await query_rag(\"What happened between 15:00 and 20:00?\", MINIO_COLLECTION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Additional query: analyze key defensive plays and turnovers.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defensive Analysis\n",
    "await query_rag(\"Describe the key defensive plays and turnovers that impacted the game outcome.\", MINIO_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Additional query: identify critical momentum-changing plays in the second half.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum Shifts\n",
    "await query_rag(\"What were the critical momentum-changing plays in the second half of the game?\", MINIO_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up\n",
    "\n",
    "Stop all services and clean up ingested data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Stop RAG Deployment\n",
    "\n",
    "Stop all RAG services (NIMs, Milvus, Ingestor, RAG server).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping RAG stack...\n",
      "$ docker compose -f deploy/compose/docker-compose-rag-server.yaml down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container rag-frontend Stopping \n",
      " Container rag-frontend Stopped \n",
      " Container rag-frontend Removing \n",
      " Container rag-frontend Removed \n",
      " Container rag-server Stopping \n",
      " Container rag-server Stopped \n",
      " Container rag-server Removing \n",
      " Container rag-server Removed \n",
      " Network nvidia-rag Removing \n",
      " Network nvidia-rag Resource is still in use \n",
      " Container compose-redis-1 Stopping \n",
      " Container compose-nv-ingest-ms-runtime-1 Stopping \n",
      " Container ingestor-server Stopping \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ docker compose -f deploy/compose/docker-compose-ingestor-server.yaml down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container compose-redis-1 Stopped \n",
      " Container compose-redis-1 Removing \n",
      " Container compose-redis-1 Removed \n",
      " Container compose-nv-ingest-ms-runtime-1 Stopped \n",
      " Container compose-nv-ingest-ms-runtime-1 Removing \n",
      " Container ingestor-server Stopped \n",
      " Container ingestor-server Removing \n",
      " Container compose-nv-ingest-ms-runtime-1 Removed \n",
      " Container ingestor-server Removed \n",
      " Network nvidia-rag Removing \n",
      " Network nvidia-rag Resource is still in use \n",
      " Container milvus-standalone Stopping \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ docker compose -f deploy/compose/vectordb.yaml down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container milvus-standalone Stopped \n",
      " Container milvus-standalone Removing \n",
      " Container milvus-standalone Removed \n",
      " Container milvus-minio Stopping \n",
      " Container milvus-etcd Stopping \n",
      " Container milvus-etcd Stopped \n",
      " Container milvus-etcd Removing \n",
      " Container milvus-etcd Removed \n",
      " Container milvus-minio Stopped \n",
      " Container milvus-minio Removing \n",
      " Container milvus-minio Removed \n",
      " Network nvidia-rag Removing \n",
      " Network nvidia-rag Resource is still in use \n",
      " Container compose-graphic-elements-1 Stopping \n",
      " Container compose-table-structure-1 Stopping \n",
      " Container nemoretriever-embedding-ms Stopping \n",
      " Container nim-llm-ms Stopping \n",
      " Container compose-paddle-1 Stopping \n",
      " Container nemoretriever-ranking-ms Stopping \n",
      " Container compose-page-elements-1 Stopping \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ docker compose -f deploy/compose/nims.yaml down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container nim-llm-ms Stopped \n",
      " Container nim-llm-ms Removing \n",
      " Container nim-llm-ms Removed \n",
      " Container compose-page-elements-1 Stopped \n",
      " Container compose-page-elements-1 Removing \n",
      " Container nemoretriever-ranking-ms Stopped \n",
      " Container nemoretriever-ranking-ms Removing \n",
      " Container nemoretriever-embedding-ms Stopped \n",
      " Container nemoretriever-embedding-ms Removing \n",
      " Container compose-page-elements-1 Removed \n",
      " Container nemoretriever-ranking-ms Removed \n",
      " Container compose-table-structure-1 Stopped \n",
      " Container compose-table-structure-1 Removing \n",
      " Container nemoretriever-embedding-ms Removed \n",
      " Container compose-table-structure-1 Removed \n",
      " Container compose-paddle-1 Stopped \n",
      " Container compose-paddle-1 Removing \n",
      " Container compose-paddle-1 Removed \n",
      " Container compose-graphic-elements-1 Stopped \n",
      " Container compose-graphic-elements-1 Removing \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] RAG stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container compose-graphic-elements-1 Removed \n",
      " Network nvidia-rag Removing \n",
      " Network nvidia-rag Resource is still in use \n"
     ]
    }
   ],
   "source": [
    "os.chdir(RAG_REPO_DIR)\n",
    "for f in [\n",
    "    \"deploy/compose/docker-compose-rag-server.yaml\",\n",
    "    \"deploy/compose/docker-compose-ingestor-server.yaml\",\n",
    "    \"deploy/compose/vectordb.yaml\",\n",
    "    \"deploy/compose/nims.yaml\",\n",
    "]:\n",
    "    run_command(f\"docker compose -f {f} down\")\n",
    "print(\"[OK] RAG stopped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stop VSS Deployment\n",
    "\n",
    "Stop all VSS services (NIMs, VLM, via-server).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping VSS stack...\n",
      "$ docker compose -f deploy/docker/local_deployment_single_gpu/compose.yaml down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container local_deployment_single_gpu-elasticsearch-1 Stopping \n",
      " Container local_deployment_single_gpu-via-server-1 Stopping \n",
      " Container local_deployment_single_gpu-via-server-1 Stopped \n",
      " Container local_deployment_single_gpu-via-server-1 Removing \n",
      " Container local_deployment_single_gpu-via-server-1 Removed \n",
      " Container local_deployment_single_gpu-minio-1 Stopping \n",
      " Container local_deployment_single_gpu-arango-db-1 Stopping \n",
      " Container local_deployment_single_gpu-graph-db-1 Stopping \n",
      " Container local_deployment_single_gpu-milvus-standalone-1 Stopping \n",
      " Container local_deployment_single_gpu-minio-1 Stopped \n",
      " Container local_deployment_single_gpu-minio-1 Removing \n",
      " Container local_deployment_single_gpu-milvus-standalone-1 Stopped \n",
      " Container local_deployment_single_gpu-milvus-standalone-1 Removing \n",
      " Container local_deployment_single_gpu-minio-1 Removed \n",
      " Container local_deployment_single_gpu-milvus-standalone-1 Removed \n",
      " Container local_deployment_single_gpu-arango-db-1 Stopped \n",
      " Container local_deployment_single_gpu-arango-db-1 Removing \n",
      " Container local_deployment_single_gpu-arango-db-1 Removed \n",
      " Container local_deployment_single_gpu-elasticsearch-1 Stopped \n",
      " Container local_deployment_single_gpu-elasticsearch-1 Removing \n",
      " Container local_deployment_single_gpu-elasticsearch-1 Removed \n",
      " Container local_deployment_single_gpu-graph-db-1 Stopped \n",
      " Container local_deployment_single_gpu-graph-db-1 Removing \n",
      " Container local_deployment_single_gpu-graph-db-1 Removed \n",
      " Network local_deployment_single_gpu_default Removing \n",
      " Network local_deployment_single_gpu_default Removed \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ docker stop vss-llm vss-embedding vss-reranker 2>/dev/null || true\n",
      "vss-llm\n",
      "vss-embedding\n",
      "vss-reranker\n",
      "$ docker rm vss-llm vss-embedding vss-reranker 2>/dev/null || true\n",
      "vss-llm\n",
      "vss-embedding\n",
      "vss-reranker\n",
      "[OK] VSS stopped\n"
     ]
    }
   ],
   "source": [
    "vss_deploy_dir = f\"{VSS_DIR}/deploy/docker/local_deployment_single_gpu\"\n",
    "if os.path.exists(vss_deploy_dir):\n",
    "    subprocess.run(f\"cd {vss_deploy_dir} && set -a && source .env 2>/dev/null && set +a && docker compose down\",\n",
    "                   shell=True, executable=\"/bin/bash\", capture_output=True)\n",
    "for name in [\"vss-llm\", \"vss-embedding\", \"vss-reranker\"]:\n",
    "    subprocess.run(f\"docker rm -f {name} 2>/dev/null\", shell=True, capture_output=True)\n",
    "print(\"[OK] VSS stopped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stop AIDP Deployment\n",
    "\n",
    "Stop AIDP services (Kafka, MinIO, Consumer).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping AIDP stack...\n",
      "$ docker compose -f /localhome/local-minhngu/aidb-helm/deploy/docker-compose-aidp.yaml down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container kafka-consumer Stopping \n",
      " Container aidp-kafka-ui Stopping \n",
      " Container aidp-minio-mc Stopping \n",
      " Container aidp-kafka-ui Stopped \n",
      " Container aidp-kafka-ui Removing \n",
      " Container aidp-kafka-ui Removed \n",
      " Container aidp-minio-mc Stopped \n",
      " Container aidp-minio-mc Removing \n",
      " Container kafka-consumer Stopped \n",
      " Container kafka-consumer Removing \n",
      " Container aidp-minio-mc Removed \n",
      " Container kafka-consumer Removed \n",
      " Container aidp-minio Stopping \n",
      " Container kafka Stopping \n",
      " Container aidp-minio Stopped \n",
      " Container aidp-minio Removing \n",
      " Container aidp-minio Removed \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] AIDP stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container kafka Stopped \n",
      " Container kafka Removing \n",
      " Container kafka Removed \n"
     ]
    }
   ],
   "source": [
    "run_command(f\"docker compose -f {AIDP_COMPOSE_FILE} down\")\n",
    "print(\"[OK] AIDP stopped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean All Ingested Documents\n",
    "\n",
    "Delete all documents from RAG collections and MinIO storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and delete all documents from RAG collection\n",
    "try:\n",
    "    resp = requests.get(f\"{INGESTOR_URL}/documents\", params={\"collection_name\": MINIO_COLLECTION}, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    documents = resp.json().get(\"documents\", [])\n",
    "except requests.RequestException as e:\n",
    "    print(f\"[ERROR] {e}\")\n",
    "    documents = []\n",
    "\n",
    "if not documents:\n",
    "    print(\"No documents to clean.\")\n",
    "else:\n",
    "    print(f\"Deleting {len(documents)} documents...\")\n",
    "    for doc in documents:\n",
    "        name = doc.get(\"document_name\")\n",
    "        if not name:\n",
    "            continue\n",
    "        try:\n",
    "            requests.delete(\n",
    "                f\"{INGESTOR_URL}/documents\",\n",
    "                json={\"document_names\": [name], \"collection_name\": MINIO_COLLECTION},\n",
    "                timeout=30,\n",
    "            ).raise_for_status()\n",
    "            print(f\"  [OK] {name}\")\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"  [ERROR] {name}: {e}\")\n",
    "    print(\"Cleanup complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}