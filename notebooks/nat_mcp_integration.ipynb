{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAT + NVIDIA RAG MCP end-to-end notebook\n",
    "\n",
    "#### What is NAT?\n",
    "\n",
    "[NeMo Agent Toolkit (NAT)](https://docs.nvidia.com/nemo/agent-toolkit/latest/index.html) is NVIDIA's framework for building, deploying, and orchestrating AI agents. NAT provides:\n",
    "\n",
    "- **Unified agent workflows**: Define complex multi-step reasoning pipelines using simple YAML configurations\n",
    "- **MCP integration**: Connect to any Model Context Protocol (MCP) server to extend agent capabilities with external tools\n",
    "- **LLM flexibility**: Use NVIDIA NIM, OpenAI, or other LLM providers interchangeably\n",
    "- **Production-ready serving**: Deploy agents as REST APIs with built-in observability and scaling\n",
    "\n",
    "#### Why use NAT with NVIDIA RAG?\n",
    "\n",
    "By combining NAT with the NVIDIA RAG MCP server, you can:\n",
    "\n",
    "1. **Build intelligent agents** that leverage your enterprise knowledge base through RAG\n",
    "2. **Enable natural language interactions** - users can ask questions, search documents, and manage collections conversationally\n",
    "3. **Extend RAG capabilities** - the agent can reason about when to search, summarize, or combine information from multiple queries\n",
    "4. **Simplify integration** - MCP provides a standard protocol for tool calling, making it easy to add RAG to any agent workflow\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Set up a virtual environment with NAT CLI and MCP dependencies using `uv`.\n",
    "2. Start the NVIDIA RAG MCP server in `streamable_http` mode.\n",
    "3. Create a collection and upload a sample document via the MCP client.\n",
    "4. Configure a NAT workflow using `nvidia_rag_mcp.yaml`.\n",
    "5. Start a NAT server that uses the RAG MCP server as a tool.\n",
    "6. Run a natural language query against the RAG workflow using `nat run`.\n",
    "7. Clean up: delete the collection, stop the servers, remove the `.nat-mcp` virtual environment and `nvidia_rag_mcp.yaml` config file.\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- End-to-end NVIDIA RAG workflow is up and running (per the [RAG quickstart](https://github.com/NVIDIA-AI-Blueprints/rag/blob/develop/docs/deploy-docker-self-hosted.md)).\n",
    "\n",
    "### Set up Virtual Environment\n",
    "\n",
    "Run the cell below to create a virtual environment and install NAT CLI and MCP dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create virtual environment using uv\n",
    "!uv venv .nat-mcp\n",
    "\n",
    "# Install NAT CLI with langchain and mcp plugins into the venv\n",
    "# See: https://docs.nvidia.com/nemo/agent-toolkit/latest/quick-start/installing.html\n",
    "!uv pip install --python .nat-mcp/bin/python \"nvidia-nat[langchain,mcp]\"\n",
    "\n",
    "# Install MCP requirements into the venv\n",
    "!uv pip install --python .nat-mcp/bin/python -r ../examples/nvidia_rag_mcp/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the MCP Server\n",
    "\n",
    "The next cell launches the NVIDIA RAG MCP server in `streamable_http` mode on port 9902. The server runs as a background subprocess and is automatically terminated when the kernel shuts down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the RAG server and INGESTOR server urls before starting the MCP server\n",
    "import os\n",
    "\n",
    "os.environ[\"INGESTOR_SERVER_URL\"] = \"http://localhost:8082\" # Ingestor server url\n",
    "os.environ[\"VITE_API_CHAT_URL\"] = \"http://localhost:8081\" # Rag server url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import atexit\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "MCP_PORT = 9902\n",
    "MCP_HOST = \"127.0.0.1\"\n",
    "\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "server_path = os.path.join(repo_root, \"examples\", \"nvidia_rag_mcp\", \"mcp_server.py\")\n",
    "\n",
    "# Use Python from the .nat-mcp venv\n",
    "venv_dir = os.path.join(os.getcwd(), \".nat-mcp\")\n",
    "venv_python = os.path.join(venv_dir, \"bin\", \"python\")\n",
    "if not os.path.exists(venv_python):\n",
    "    raise RuntimeError(f\"Python not found at {venv_python}. Please run the installation cell first.\")\n",
    "\n",
    "cmd = [\n",
    "    venv_python,\n",
    "    server_path,\n",
    "    \"--transport\",\n",
    "    \"streamable_http\",\n",
    "    \"--host\",\n",
    "    MCP_HOST,\n",
    "    \"--port\",\n",
    "    str(MCP_PORT),\n",
    "]\n",
    "\n",
    "print(\"Launching MCP server:\", \" \".join(cmd))\n",
    "\n",
    "mcp_proc = subprocess.Popen(cmd)\n",
    "atexit.register(lambda: mcp_proc and mcp_proc.poll() is None and mcp_proc.terminate())\n",
    "\n",
    "time.sleep(2.0)\n",
    "print(f\"MCP server PID: {mcp_proc.pid} (http://{MCP_HOST}:{MCP_PORT}/mcp)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Collection and Upload a Document\n",
    "\n",
    "The next cell uses the MCP client to create a collection and upload a sample PDF document. This demonstrates how to interact with the NVIDIA RAG MCP server programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "STREAMABLE_HTTP_URL = \"http://127.0.0.1:9902/mcp\"\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "client_path = os.path.join(repo_root, \"examples\", \"nvidia_rag_mcp\", \"mcp_client.py\")\n",
    "\n",
    "# Use Python from the .nat-mcp venv\n",
    "venv_dir = os.path.join(os.getcwd(), \".nat-mcp\")\n",
    "venv_python = os.path.join(venv_dir, \"bin\", \"python\")\n",
    "if not os.path.exists(venv_python):\n",
    "    raise RuntimeError(f\"Python not found at {venv_python}. Please run the installation cell first.\")\n",
    "\n",
    "COLLECTION = \"my_collection\"\n",
    "pdf_path = os.path.join(repo_root, \"data\", \"multimodal\", \"product_catalog.pdf\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Creating collection via MCP...\")\n",
    "print(\"=\" * 80)\n",
    "# Use create_collection (singular) with collection_name (not collection_names)\n",
    "create_args = json.dumps({\"collection_name\": COLLECTION})\n",
    "subprocess.run([\n",
    "    venv_python,\n",
    "    client_path,\n",
    "    \"call\",\n",
    "    \"--transport=streamable_http\",\n",
    "    f\"--url={STREAMABLE_HTTP_URL}\",\n",
    "    \"--tool=create_collection\",\n",
    "    f\"--json-args={create_args}\",\n",
    "], check=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Uploading document via MCP...\")\n",
    "print(\"=\" * 80)\n",
    "upload_args = json.dumps({\n",
    "    \"collection_name\": COLLECTION,\n",
    "    \"file_paths\": [pdf_path],\n",
    "    \"blocking\": True,\n",
    "    \"generate_summary\": True,\n",
    "    \"split_options\": {\"chunk_size\": 512, \"chunk_overlap\": 150},\n",
    "})\n",
    "subprocess.run([\n",
    "    venv_python,\n",
    "    client_path,\n",
    "    \"call\",\n",
    "    \"--transport=streamable_http\",\n",
    "    f\"--url={STREAMABLE_HTTP_URL}\",\n",
    "    \"--tool=upload_documents\",\n",
    "    f\"--json-args={upload_args}\",\n",
    "], check=False)\n",
    "\n",
    "print(\"\\nDone setting up collection and document for NAT + MCP demo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `nvidia_rag_mcp.yaml` for NAT\n",
    "\n",
    "The next cell creates a file named `nvidia_rag_mcp.yaml` in the project root directory. This YAML configuration:\n",
    "- **Defines an MCP client** (`function_groups.nvidia_rag_mcp`) that connects to the NVIDIA RAG MCP server over `streamable-http` at `http://localhost:9902/mcp` and exposes the `generate` tool to NAT.\n",
    "- **Configures the LLM** (`llms.nim_llm`) that the agent uses when deciding how to call the MCP tool.\n",
    "- **Builds a ReAct agent workflow** (`workflow`) that wires the `nvidia_rag_mcp` tool group and `nim_llm` model together.\n",
    "\n",
    "You normally only need to modify the generated file if you:\n",
    "- Point the MCP server to a different host/port (update the `url`), or\n",
    "- Want to use a different LLM (update `model_name` and related settings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "config_path = os.path.join(repo_root, \"nvidia_rag_mcp.yaml\")\n",
    "\n",
    "config_content = \"\"\"\\\n",
    "function_groups:\n",
    "  nvidia_rag_mcp:\n",
    "    _type: mcp_client\n",
    "    server:\n",
    "      transport: streamable-http\n",
    "      url: \"http://localhost:9902/mcp\"\n",
    "    include:\n",
    "      - generate\n",
    "\n",
    "llms:\n",
    "  nim_llm:\n",
    "    _type: nim\n",
    "    model_name: meta/llama-3.1-70b-instruct\n",
    "    temperature: 0.0\n",
    "    max_tokens: 1024\n",
    "\n",
    "workflow:\n",
    "  _type: react_agent\n",
    "  tool_names:\n",
    "    - nvidia_rag_mcp\n",
    "  llm_name: nim_llm\n",
    "  verbose: true\n",
    "  retry_parsing_errors: true\n",
    "  max_retries: 3\n",
    "\"\"\"\n",
    "\n",
    "with open(config_path, \"w\") as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(f\"Created NAT config file: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the NAT server\n",
    "\n",
    "The next cell launches `nat serve` as a background subprocess. Leave the kernel running while you execute subsequent cells to query via `nat run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import atexit\n",
    "import time\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "NAT_PORT = 8000\n",
    "MCP_URL = \"http://127.0.0.1:9902/mcp\"\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "config_path = os.path.join(repo_root, \"nvidia_rag_mcp.yaml\")\n",
    "\n",
    "# Use Python/nat from the .nat-mcp venv\n",
    "venv_dir = os.path.join(os.getcwd(), \".nat-mcp\")\n",
    "venv_nat = os.path.join(venv_dir, \"bin\", \"nat\")\n",
    "if not os.path.exists(venv_nat):\n",
    "    raise RuntimeError(f\"NAT not found at {venv_nat}. Please run the installation cell first.\")\n",
    "\n",
    "# First, verify the MCP server is running\n",
    "print(f\"Checking MCP server at {MCP_URL}...\")\n",
    "try:\n",
    "    req = urllib.request.Request(MCP_URL, method='POST')\n",
    "    req.add_header('Content-Type', 'application/json')\n",
    "    with urllib.request.urlopen(req, timeout=5) as resp:\n",
    "        print(f\"MCP server is reachable (status: {resp.status})\")\n",
    "except urllib.error.HTTPError as e:\n",
    "    # HTTP errors like 400/405 mean the server is running\n",
    "    print(f\"MCP server is reachable (HTTP {e.code})\")\n",
    "except urllib.error.URLError as e:\n",
    "    print(f\"ERROR: Cannot connect to MCP server at {MCP_URL}\")\n",
    "    print(f\"  Reason: {e.reason}\")\n",
    "    print(\"\\nPlease ensure the MCP server is running (run Cell 2 first).\")\n",
    "    print(\"If port 9902 is in use, run: fuser -k 9902/tcp\")\n",
    "    raise RuntimeError(\"MCP server not reachable\") from e\n",
    "\n",
    "cmd = [venv_nat, \"serve\", \"--config_file\", config_path, \"--port\", str(NAT_PORT)]\n",
    "\n",
    "print(f\"Launching NAT server on port {NAT_PORT}...\")\n",
    "\n",
    "nat_proc = subprocess.Popen(cmd, cwd=repo_root)\n",
    "atexit.register(lambda: nat_proc and nat_proc.poll() is None and nat_proc.terminate())\n",
    "\n",
    "time.sleep(5.0)\n",
    "\n",
    "# Check if process is still running\n",
    "if nat_proc.poll() is None:\n",
    "    print(f\"NAT server PID: {nat_proc.pid} (http://127.0.0.1:{NAT_PORT})\")\n",
    "else:\n",
    "    print(f\"NAT server exited with code: {nat_proc.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run `nat run`\n",
    "\n",
    "The next cell executes `nat run` to invoke the workflow defined in `nvidia_rag_mcp.yaml`. This uses the NVIDIA RAG MCP server (running on `http://localhost:9902/mcp`) to answer based on the document you uploaded.\n",
    "\n",
    "**Important:** Set your `NVIDIA_API_KEY` before running this cell. Get your API key from [build.nvidia.com](https://build.nvidia.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del os.environ['NVIDIA_API_KEY']  ## delete key and reset if needed\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    print(\"Valid NVIDIA_API_KEY already in environment. Delete to reset\")\n",
    "else:\n",
    "    candidate_api_key = getpass(\"NVAPI Key (starts with nvapi-): \")\n",
    "    assert candidate_api_key.startswith(\"nvapi-\"), (\n",
    "        f\"{candidate_api_key[:5]}... is not a valid key\"\n",
    "    )\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = candidate_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Set your NVIDIA API key here\n",
    "# You can also set this as an environment variable before starting Jupyter\n",
    "NVIDIA_API_KEY = os.environ.get(\"NVIDIA_API_KEY\", \"nvapi-...\")\n",
    "if NVIDIA_API_KEY == \"nvapi-...\":\n",
    "    raise ValueError(\"Please set your NVIDIA_API_KEY. Get one from https://build.nvidia.com/\")\n",
    "\n",
    "COLLECTION = \"my_collection\"\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "config_path = os.path.join(repo_root, \"nvidia_rag_mcp.yaml\")\n",
    "\n",
    "query = f\"My rag question is: Tell me about Ratan Basket Shoulder Bag. Use collection {COLLECTION}, with ranker model as nvidia/llama-3.2-nv-rerankqa-1b-v2\"\n",
    "\n",
    "# Use nat from the .nat-mcp venv\n",
    "venv_dir = os.path.join(os.getcwd(), \".nat-mcp\")\n",
    "venv_nat = os.path.join(venv_dir, \"bin\", \"nat\")\n",
    "if not os.path.exists(venv_nat):\n",
    "    raise RuntimeError(f\"NAT not found at {venv_nat}. Please run the installation cell first.\")\n",
    "\n",
    "# Prepare environment with API key\n",
    "env = os.environ.copy()\n",
    "env[\"NVIDIA_API_KEY\"] = NVIDIA_API_KEY\n",
    "\n",
    "cmd = [venv_nat, \"run\", \"--config_file\", config_path, \"--input\", query]\n",
    "\n",
    "print(\"Running NAT query...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = subprocess.run(cmd, cwd=repo_root, capture_output=True, text=True, env=env)\n",
    "\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"STDERR:\", result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up: Delete the demo collection\n",
    "\n",
    "Run the next cell after you are done experimenting with the RAG workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "STREAMABLE_HTTP_URL = \"http://127.0.0.1:9902/mcp\"\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "client_path = os.path.join(repo_root, \"examples\", \"nvidia_rag_mcp\", \"mcp_client.py\")\n",
    "\n",
    "# Use Python from the .nat-mcp venv\n",
    "venv_dir = os.path.join(os.getcwd(), \".nat-mcp\")\n",
    "venv_python = os.path.join(venv_dir, \"bin\", \"python\")\n",
    "if not os.path.exists(venv_python):\n",
    "    raise RuntimeError(f\"Python not found at {venv_python}. Please run the installation cell first.\")\n",
    "\n",
    "COLLECTION = \"my_collection\"\n",
    "\n",
    "print(\"Deleting collection via MCP...\\n\")\n",
    "delete_args = json.dumps({\"collection_names\": [COLLECTION]})\n",
    "subprocess.run([\n",
    "    venv_python,\n",
    "    client_path,\n",
    "    \"call\",\n",
    "    \"--transport=streamable_http\",\n",
    "    f\"--url={STREAMABLE_HTTP_URL}\",\n",
    "    \"--tool=delete_collections\",\n",
    "    f\"--json-args={delete_args}\",\n",
    "], check=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the NAT server\n",
    "\n",
    "The next cell stops the NAT server that was started earlier in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nat_proc\n",
    "except NameError:\n",
    "    print(\"No NAT server process handle (`nat_proc`) found in this session.\")\n",
    "else:\n",
    "    if nat_proc is not None and nat_proc.poll() is None:\n",
    "        print(f\"Terminating NAT server PID {nat_proc.pid}...\")\n",
    "        nat_proc.terminate()\n",
    "        try:\n",
    "            nat_proc.wait(timeout=10)\n",
    "        except Exception:\n",
    "            print(\"NAT server did not exit in time; sending kill()...\")\n",
    "            nat_proc.kill()\n",
    "        print(\"NAT server stopped.\")\n",
    "    else:\n",
    "        print(\"NAT server process is not running.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the MCP server\n",
    "\n",
    "The next cell stops the MCP server that was started at the beginning of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mcp_proc\n",
    "except NameError:\n",
    "    print(\"No MCP server process handle (`mcp_proc`) found in this session.\")\n",
    "else:\n",
    "    if mcp_proc is not None and mcp_proc.poll() is None:\n",
    "        print(f\"Terminating MCP server PID {mcp_proc.pid}...\")\n",
    "        mcp_proc.terminate()\n",
    "        try:\n",
    "            mcp_proc.wait(timeout=10)\n",
    "        except Exception:\n",
    "            print(\"MCP server did not exit in time; sending kill()...\")\n",
    "            mcp_proc.kill()\n",
    "        print(\"MCP server stopped.\")\n",
    "    else:\n",
    "        print(\"MCP server process is not running.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up: Delete virtual environment and config file\n",
    "\n",
    "Run the next cell to remove the `.nat-mcp` virtual environment and the `nvidia_rag_mcp.yaml` config file created during this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Delete .nat-mcp virtual environment\n",
    "venv_dir = os.path.join(os.getcwd(), \".nat-mcp\")\n",
    "if os.path.exists(venv_dir):\n",
    "    print(f\"Deleting virtual environment: {venv_dir}\")\n",
    "    shutil.rmtree(venv_dir)\n",
    "    print(\"Virtual environment deleted.\")\n",
    "else:\n",
    "    print(f\"Virtual environment not found at {venv_dir}\")\n",
    "\n",
    "# Delete nvidia_rag_mcp.yaml config file\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "config_path = os.path.join(repo_root, \"nvidia_rag_mcp.yaml\")\n",
    "if os.path.exists(config_path):\n",
    "    print(f\"Deleting config file: {config_path}\")\n",
    "    os.remove(config_path)\n",
    "    print(\"Config file deleted.\")\n",
    "else:\n",
    "    print(f\"Config file not found at {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting\n",
    "\n",
    "- **`uv` not found or virtual environment setup fails**\n",
    "  - Install `uv` first: `pip install uv` or follow the [uv installation guide](https://docs.astral.sh/uv/getting-started/installation/).\n",
    "  - If the virtual environment already exists, delete `.nat-mcp/` and rerun the setup cell.\n",
    "\n",
    "- **MCP server fails to start or hangs**\n",
    "  - Check that NVIDIA RAG and Ingestor services are up and healthy (see the [RAG quickstart](https://github.com/NVIDIA-AI-Blueprints/rag/blob/develop/docs/deploy-docker-self-hosted.md)).\n",
    "  - Ensure port `9902` is free: `fuser -k 9902/tcp` (Linux) and rerun the server cell.\n",
    "\n",
    "- **MCP client calls (create/upload/delete) fail**\n",
    "  - Verify the MCP server cell printed a valid PID and URL `http://127.0.0.1:9902/mcp`.\n",
    "  - Run the MCP client commands from the notebook again and inspect any error text in the cell output.\n",
    "\n",
    "- **`nat serve` cannot connect to MCP**\n",
    "  - Confirm the MCP server cell is still running (no error in its output, and the stop-MCP cell reports it as running).\n",
    "  - Make sure the `url` in `nvidia_rag_mcp.yaml` matches the MCP server address (default: `http://localhost:9902/mcp`).\n",
    "\n",
    "- **`nat run` errors or returns empty/irrelevant answers**\n",
    "  - Ensure your `NVIDIA_API_KEY` is set correctly. Get one from [build.nvidia.com](https://build.nvidia.com/).\n",
    "  - Confirm the collection (`my_collection`) exists and the upload cell completed successfully.\n",
    "  - Adjust the `--input` prompt to clearly mention the collection name and the document you uploaded.\n",
    "\n",
    "- **Environment or dependency issues**\n",
    "  - Ensure you ran the virtual environment setup cell first (it installs `nvidia-nat[langchain,mcp]`).\n",
    "  - If dependencies are missing, delete the `.nat-mcp/` folder and rerun the setup cell.\n",
    "  - See the [NeMo Agent Toolkit installation guide](https://docs.nvidia.com/nemo/agent-toolkit/latest/quick-start/installing.html) for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-library",
   "language": "python",
   "name": "rag-library"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
