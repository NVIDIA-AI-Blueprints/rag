# ==== Authentication ====
export NVIDIA_API_KEY=${NGC_API_KEY}

# ==== Service-Specific API Keys (Optional) ====
# Set these to use different API keys for individual services.
# If not set or empty, all services use NVIDIA_API_KEY as fallback.
# export APP_LLM_APIKEY=""
# export APP_EMBEDDINGS_APIKEY=""
# export APP_RANKING_APIKEY=""
# export APP_QUERYREWRITER_APIKEY=""
# export APP_FILTEREXPRESSIONGENERATOR_APIKEY=""
# export APP_VLM_APIKEY=""
# export SUMMARY_LLM_APIKEY=""
# export REFLECTION_LLM_APIKEY=""

# === Internally NVIDIA hosted NIM Endpoints (for cloud deployment) ===
# WAR: Use public endpoint for inference
export APP_LLM_MODELNAME=nvidia/llama-3.3-nemotron-super-49b-v1.5
# For nemotron-3-nano models hosted on NVIDIA cloud, use:
# export APP_LLM_MODELNAME=nvidia/nemotron-3-nano-30b-a3b
# Note: For locally deployed nemotron-3-nano, use: nvidia/nemotron-3-nano
export APP_FILTEREXPRESSIONGENERATOR_MODELNAME=nvidia/llama-3.3-nemotron-super-49b-v1.5
export APP_EMBEDDINGS_MODELNAME=nvdev/nvidia/llama-3.2-nv-embedqa-1b-v2
# For VLM Embedding Model (Nemoretriever-1b-vlm-embed-v1)
# export APP_EMBEDDINGS_MODELNAME=nvdev/nvidia/llama-nemotron-embed-vl-1b-v2
export APP_RANKING_MODELNAME=nvidia/llama-3.2-nv-rerankqa-1b-v2
export ENABLE_RERANKER=True
export APP_EMBEDDINGS_SERVERURL=https://integrate.api.nvidia.com/v1
export APP_LLM_SERVERURL=""
export APP_FILTEREXPRESSIONGENERATOR_SERVERURL=""
export APP_RANKING_SERVERURL=""
# export APP_RANKING_SERVERURL=https://ai.api.nvidia.com/v1/nvdev/retrieval/nvidia/llama-3_2-nv-rerankqa-1b-v2/reranking/v1
export OCR_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/nvidia/nemoretriever-ocr
export OCR_INFER_PROTOCOL=http
export OCR_MODEL_NAME=scene_text_ensemble
export YOLOX_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/nvidia/nemoretriever-page-elements-v3
export YOLOX_INFER_PROTOCOL=http
export YOLOX_GRAPHIC_ELEMENTS_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/nvdev/nvidia/nemoretriever-graphic-elements-v1
export YOLOX_GRAPHIC_ELEMENTS_INFER_PROTOCOL=http
export YOLOX_TABLE_STRUCTURE_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/nvdev/nvidia/nemoretriever-table-structure-v1
export YOLOX_TABLE_STRUCTURE_INFER_PROTOCOL=http
export SUMMARY_LLM="nvidia/llama-3.3-nemotron-super-49b-v1.5"
export SUMMARY_LLM_SERVERURL=""

# Reflection feature
export REFLECTION_LLM="nvidia/llama-3.3-nemotron-super-49b-v1.5"
export REFLECTION_LLM_SERVERURL=""
# export ENABLE_REFLECTION="True" # Uncomment to enable reflection

# To avoid OOM issues dev systems
export NV_INGEST_MAX_UTIL=8

# Nemotron parse feature
# export NEMOTRON_PARSE_HTTP_ENDPOINT=https://integrate.api.nvidia.com/v1/chat/completions # Uncomment to use NEMOTRON_PARSE nvdev model
# export NEMOTRON_PARSE_MODEL_NAME=nvidia/nemotron-parse # Uncomment to use NEMOTRON_PARSE model
# export NEMOTRON_PARSE_INFER_PROTOCOL=http # Uncomment to use NEMOTRON_PARSE protocol
# export APP_NVINGEST_PDFEXTRACTMETHOD=nemotron_parse

# VLM generation feature
export APP_VLM_SERVERURL="https://integrate.api.nvidia.com/v1"
export APP_VLM_MODELNAME="nvidia/nemotron-nano-12b-v2-vl"
# export ENABLE_VLM_INFERENCE="true" # Uncomment to use VLM generation

# Image captioning feature
export APP_NVINGEST_CAPTIONMODELNAME="nvidia/nemotron-nano-12b-v2-vl"
export APP_NVINGEST_CAPTIONENDPOINTURL="https://integrate.api.nvidia.com/v1/chat/completions"
# export APP_NVINGEST_EXTRACTIMAGES="True" # Uncomment to use image captioning

# Nemoguardrails feature
export DEFAULT_CONFIG=nemoguard_cloud
export NIM_ENDPOINT_URL=https://integrate.api.nvidia.com/v1
# export ENABLE_GUARDRAILS="True" # Uncomment to use nemo guardrails

# Query rewriter feature
export APP_QUERYREWRITER_SERVERURL=""
export APP_QUERYREWRITER_MODELNAME="nvidia/llama-3.3-nemotron-super-49b-v1.5"
# export ENABLE_QUERYREWRITER="True" # Uncomment to enable query rewriting
# export MULTITURN_RETRIEVER_SIMPLE="True" # Enable/disable concatenating conversation history with query for retrieval (when query rewriter is disabled, default: False)